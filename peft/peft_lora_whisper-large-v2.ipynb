{"cells":[{"cell_type":"markdown","id":"c219841f-493c-40f9-a6c9-3700f0c525d0","metadata":{"id":"c219841f-493c-40f9-a6c9-3700f0c525d0"},"source":["# PEFT 库 LoRA 实战 - OpenAI Whisper-large-v2\n","\n","本教程使用 LoRA 在`OpenAI Whisper-large-v2`模型上实现`语音识别(ASR)`任务的微调训练。\n","\n","同时，我们还结合了`int8` 量化进一步降低训练过程资源开销，同时保证了精度几乎不受影响。\n","\n","![LoRA](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png)\n","\n","本教程主要训练流程如下：\n","- 全局参数设置\n","- 数据准备\n","    - 下载数据集：训练、验证和评估集\n","    - 预处理数据：降采样、移除不必要字段等\n","    - 数据抽样（演示需要）\n","    - 应用数据集处理（`Dataset.map`）\n","    - 自定义语音数据处理器\n","- 模型准备\n","    - 加载和处理 `int8` 精度 Whisper-Large-v2 模型\n","    - LoRA Adapter 参数配置\n","    - 实例化 PEFT Model：`peft_model = get_peft_model(model, config)`\n","- 模型训练\n","    - 训练参数配置 Seq2SeqTrainingArguments\n","    - 实例化训练器 Seq2SeqTrainer\n","    - 训练模型\n","    - 保存模型\n","- 模型推理\n","    - 使用 `PeftModel` 加载 LoRA 微调后 Whisper 模型\n","    - 使用 `Pipeline API` 部署微调后 Whisper 实现中文语音识别任务"]},{"cell_type":"markdown","id":"6d0a1e23-ea71-45d6-82d6-453077cf2d29","metadata":{"id":"6d0a1e23-ea71-45d6-82d6-453077cf2d29"},"source":["## 全局参数设置"]},{"cell_type":"code","execution_count":1,"id":"ccd00402-d821-485e-8703-fb16bcb56a9e","metadata":{"id":"ccd00402-d821-485e-8703-fb16bcb56a9e","executionInfo":{"status":"ok","timestamp":1712316896024,"user_tz":-480,"elapsed":590,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["model_name_or_path = \"openai/whisper-large-v2\"\n","model_dir = \"models/whisper-large-v2-asr-int8\"\n","\n","language = \"Chinese (China)\"\n","language_abbr = \"zh-CN\"\n","task = \"transcribe\"\n","dataset_name = \"mozilla-foundation/common_voice_11_0\"\n","\n","batch_size=64"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ivUnfxKT4CI","executionInfo":{"status":"ok","timestamp":1712316900791,"user_tz":-480,"elapsed":3831,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"e905e1a3-7b14-4617-bb3c-279a3920b658"},"id":"0ivUnfxKT4CI","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install datasets transformers peft\n","!pip install accelerate -U\n","!pip install -i https://pypi.org/simple/ bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMGeW1OaTyjd","executionInfo":{"status":"ok","timestamp":1712316917015,"user_tz":-480,"elapsed":16226,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"974fbc06-1576-4ecd-e0f3-d1a7eb07da68"},"id":"WMGeW1OaTyjd","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.28.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Looking in indexes: https://pypi.org/simple/\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"]}]},{"cell_type":"markdown","id":"cfffa1df-e51e-4026-9817-1cebddf0061a","metadata":{"id":"cfffa1df-e51e-4026-9817-1cebddf0061a"},"source":["## 数据准备\n","\n","### 下载数据集 Common Voice\n","\n","Common Voice 11.0 数据集包含许多不同语言的录音，总时长达数小时。\n","\n","本教程以中文数据为例，展示如何使用 LoRA 在 Whisper-large-v2 上进行微调训练。\n","\n","首先，初始化一个DatasetDict结构，并将训练集（将训练+验证拆分为训练集）和测试集拆分好，按照中文数据集构建配置加载到内存中："]},{"cell_type":"code","execution_count":4,"id":"21ff42f4-f3ec-46d3-b0c0-dd9ffbf7b50b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21ff42f4-f3ec-46d3-b0c0-dd9ffbf7b50b","outputId":"e5fbf37e-f780-46f0-f73d-9efe7631fc5f","executionInfo":{"status":"ok","timestamp":1712316930615,"user_tz":-480,"elapsed":13618,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'client_id': '95368aab163e0387e4fd4991b4f2d8ccfbd4364bf656c860230501fd27dcedf087773e4695a6cf5de9c4f1d406d582283190d065cdfa36b0e2b060cffaca977e',\n"," 'path': '/root/.cache/huggingface/datasets/downloads/extracted/dcc5967c754d4c815fc005d6e297d84537028996cbcf6b34190517630cbc40b4/zh-CN_train_0/common_voice_zh-CN_33211332.mp3',\n"," 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/dcc5967c754d4c815fc005d6e297d84537028996cbcf6b34190517630cbc40b4/zh-CN_train_0/common_voice_zh-CN_33211332.mp3',\n","  'array': array([-6.82121026e-13, -2.27373675e-12, -2.27373675e-12, ...,\n","          1.21667399e-05,  3.23003678e-06, -2.43066324e-07]),\n","  'sampling_rate': 48000},\n"," 'sentence': '性喜温暖润湿气候且耐寒。',\n"," 'up_votes': 2,\n"," 'down_votes': 0,\n"," 'age': '',\n"," 'gender': '',\n"," 'accent': '',\n"," 'locale': 'zh-CN',\n"," 'segment': ''}"]},"metadata":{},"execution_count":4}],"source":["from datasets import load_dataset, DatasetDict\n","\n","common_voice = DatasetDict()\n","\n","common_voice[\"train\"] = load_dataset(dataset_name, language_abbr, split=\"train\", trust_remote_code=True)\n","common_voice[\"validation\"] = load_dataset(dataset_name, language_abbr, split=\"validation\", trust_remote_code=True)\n","\n","common_voice[\"train\"][0]"]},{"cell_type":"code","execution_count":5,"id":"9bed4735-d485-435f-b282-2806241e0e54","metadata":{"id":"9bed4735-d485-435f-b282-2806241e0e54","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316930615,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"f6b4928b-58b5-4a54-fbb5-fc3711965fa3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n","        num_rows: 29056\n","    })\n","    validation: Dataset({\n","        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n","        num_rows: 10581\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["common_voice"]},{"cell_type":"markdown","id":"3c81faa4-d8fe-4cc7-afe6-4c2615b9050f","metadata":{"id":"3c81faa4-d8fe-4cc7-afe6-4c2615b9050f"},"source":["## 预处理训练数据集\n"]},{"cell_type":"code","execution_count":6,"id":"5822025f-7f8e-4141-8bfe-d8822d0da20f","metadata":{"id":"5822025f-7f8e-4141-8bfe-d8822d0da20f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":8673,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"e957ccdb-3fb5-44e8-880b-c9ae534a5990"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import AutoFeatureExtractor, AutoTokenizer, AutoProcessor\n","\n","# 从预训练模型加载特征提取器\n","feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n","\n","# 从预训练模型加载分词器，可以指定语言和任务以获得最适合特定需求的分词器配置\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n","\n","# 从预训练模型加载处理器，处理器通常结合了特征提取器和分词器，为特定任务提供一站式的数据预处理\n","processor = AutoProcessor.from_pretrained(model_name_or_path, language=language, task=task)"]},{"cell_type":"markdown","id":"f394e5cd-23b8-413e-8bde-88c3542b84fa","metadata":{"id":"f394e5cd-23b8-413e-8bde-88c3542b84fa"},"source":["#### 移除数据集中不必要的字段"]},{"cell_type":"code","execution_count":7,"id":"1690dc5a-c1f7-4556-9be3-d31ad888e52e","metadata":{"id":"1690dc5a-c1f7-4556-9be3-d31ad888e52e","executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":25,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["common_voice = common_voice.remove_columns(\n","    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",")"]},{"cell_type":"code","execution_count":8,"id":"309aff16-ea26-4474-af54-7ef244783999","metadata":{"id":"309aff16-ea26-4474-af54-7ef244783999","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"3e4551cd-3ccf-4966-c49d-330c663f70d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/dcc5967c754d4c815fc005d6e297d84537028996cbcf6b34190517630cbc40b4/zh-CN_train_0/common_voice_zh-CN_33211332.mp3',\n","  'array': array([-6.82121026e-13, -2.27373675e-12, -2.27373675e-12, ...,\n","          1.21667399e-05,  3.23003678e-06, -2.43066324e-07]),\n","  'sampling_rate': 48000},\n"," 'sentence': '性喜温暖润湿气候且耐寒。'}"]},"metadata":{},"execution_count":8}],"source":["common_voice[\"train\"][0]"]},{"cell_type":"markdown","id":"881546ab-72e4-4bcf-852f-a8be736164b7","metadata":{"id":"881546ab-72e4-4bcf-852f-a8be736164b7"},"source":["#### 降采样音频数据\n","\n","查看`common_voice` 数据集介绍，你会发现其音频是以48kHz的采样率进行采样的.\n","\n","而`Whisper`模型是在16kHZ的音频输入上预训练的，因此我们需要将音频输入降采样以匹配模型预训练时使用的采样率。\n","\n","通过在音频列上使用`cast_column`方法，并将`sampling_rate`设置为16kHz来对音频进行降采样。\n","\n","下次调用时，音频输入将实时重新取样："]},{"cell_type":"code","execution_count":9,"id":"5fc451cc-e21e-473c-a702-d7d6ed098f91","metadata":{"id":"5fc451cc-e21e-473c-a702-d7d6ed098f91","executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":22,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["from datasets import Audio\n","\n","common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"]},{"cell_type":"code","execution_count":10,"id":"cc3d7fcc-7c34-41c8-9857-5a6e883f6115","metadata":{"id":"cc3d7fcc-7c34-41c8-9857-5a6e883f6115","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"64840e20-80ec-49b9-caaa-dcdcbf813bc3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/dcc5967c754d4c815fc005d6e297d84537028996cbcf6b34190517630cbc40b4/zh-CN_train_0/common_voice_zh-CN_33211332.mp3',\n","  'array': array([ 5.09317033e-11, -7.27595761e-12, -6.54836185e-11, ...,\n","         -5.96661994e-06,  2.71382887e-05,  1.29687978e-05]),\n","  'sampling_rate': 16000},\n"," 'sentence': '性喜温暖润湿气候且耐寒。'}"]},"metadata":{},"execution_count":10}],"source":["# sampling_rate 从 48KHZ 降为 16KHZ\n","common_voice[\"train\"][0]"]},{"cell_type":"markdown","id":"ee55908f-3ea3-4aee-8062-6f8d3a6573b9","metadata":{"id":"ee55908f-3ea3-4aee-8062-6f8d3a6573b9"},"source":["### 整合以上数据处理为一个函数\n","\n","该数据预处理函数应该包括：\n","- 通过加载音频列将音频输入重新采样为16kHZ。\n","- 使用特征提取器从音频数组计算输入特征。\n","- 将句子列标记化为输入标签。"]},{"cell_type":"code","execution_count":11,"id":"58f42c35-35ba-4d6b-9d15-095963cec67c","metadata":{"id":"58f42c35-35ba-4d6b-9d15-095963cec67c","executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["def prepare_dataset(batch):\n","    audio = batch[\"audio\"]\n","    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n","    return batch"]},{"cell_type":"code","execution_count":11,"id":"d3a04c60-09be-419c-bdc6-6d56bbf9d4d0","metadata":{"id":"d3a04c60-09be-419c-bdc6-6d56bbf9d4d0","executionInfo":{"status":"ok","timestamp":1712316939284,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"a8923262-f881-476f-9806-61a3c8fb8518","metadata":{"id":"a8923262-f881-476f-9806-61a3c8fb8518"},"source":["### 数据抽样（演示需要）\n","\n","在 Whisper-Large-v2 上使用小规模数据进行演示训练，保持以下训练参数不变（batch_size=64）。\n","\n","使用 640 个样本训练，320个样本验证和评估，恰好使得1个 epoch 仅需10 steps 即可完成训练。\n","\n","（在 NVIDIA T4 上需要10-15分钟）"]},{"cell_type":"code","execution_count":12,"id":"28b14693-aa42-4f13-a537-66b5c4cb4718","metadata":{"id":"28b14693-aa42-4f13-a537-66b5c4cb4718","executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["small_common_voice = DatasetDict()\n","\n","small_common_voice[\"train\"] = common_voice[\"train\"].shuffle(seed=16)\n","small_common_voice[\"validation\"] = common_voice[\"validation\"].shuffle(seed=16)"]},{"cell_type":"code","execution_count":13,"id":"46b6a10b-81a9-428d-8130-4c2b626f3ba3","metadata":{"id":"46b6a10b-81a9-428d-8130-4c2b626f3ba3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":16,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"7d3b690a-8522-42aa-a173-23dbe8a59cba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 29056\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence'],\n","        num_rows: 10581\n","    })\n","})"]},"metadata":{},"execution_count":13}],"source":["small_common_voice"]},{"cell_type":"markdown","id":"5a40f480-6eeb-4546-891b-97ec4a7ec46d","metadata":{"id":"5a40f480-6eeb-4546-891b-97ec4a7ec46d"},"source":["### 如果全量训练，则使用完整数据代替抽样"]},{"cell_type":"code","execution_count":14,"id":"392f7856-a720-40a7-af7e-40e185fc315b","metadata":{"id":"392f7856-a720-40a7-af7e-40e185fc315b","executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":11,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["# 抽样数据处理\n","tokenized_common_voice = small_common_voice.map(prepare_dataset)\n","\n","# 完整数据训练，尝试开启 `num_proc=8` 参数多进程并行处理（如阻塞无法运行，则不使用此参数）\n","# tokenized_common_voice = common_voice.map(prepare_dataset, num_proc=8)"]},{"cell_type":"code","execution_count":15,"id":"76646516-06e2-4700-92fe-4fbb87587e31","metadata":{"id":"76646516-06e2-4700-92fe-4fbb87587e31","outputId":"ef0786d3-7a28-4e98-ff76-6bf1e5d8fc14","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['audio', 'sentence', 'input_features', 'labels'],\n","        num_rows: 29056\n","    })\n","    validation: Dataset({\n","        features: ['audio', 'sentence', 'input_features', 'labels'],\n","        num_rows: 10581\n","    })\n","})"]},"metadata":{},"execution_count":15}],"source":["tokenized_common_voice"]},{"cell_type":"markdown","id":"84ec184e-d840-40b6-99af-d11392273442","metadata":{"id":"84ec184e-d840-40b6-99af-d11392273442"},"source":["### 自定义语音数据整理器\n","\n","定义了一个针对语音到文本（Seq2Seq）模型的自定义数据整理器类，特别适用于输入为语音特征、输出为文本序列的数据集。\n","\n","\n","这个整理器（`DataCollatorSpeechSeq2SeqWithPadding`）旨在将数据点批量打包，将每个批次中的`attention_mask`填充到最大长度，以保持批处理中张量形状的一致性，并用`-100`替换填充值，以便在损失函数中被忽略。这对于神经网络的高效训练至关重要。"]},{"cell_type":"code","execution_count":16,"id":"4c89ffcf-c805-48c2-b7d3-ae01b687178c","metadata":{"id":"4c89ffcf-c805-48c2-b7d3-ae01b687178c","executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["import torch\n","\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","# 定义一个针对语音到文本任务的数据整理器类\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any  # 处理器结合了特征提取器和分词器\n","\n","    # 整理器函数，将特征列表处理成一个批次\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # 从特征列表中提取输入特征，并填充以使它们具有相同的形状\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        # 从特征列表中提取标签特征（文本令牌），并进行填充\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # 使用-100替换标签中的填充区域，-100通常用于在损失计算中忽略填充令牌\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # 如果批次中的所有序列都以句子开始令牌开头，则移除它\n","        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        # 将处理过的标签添加到批次中\n","        batch[\"labels\"] = labels\n","\n","        return batch  # 返回最终的批次，准备好进行训练或评估"]},{"cell_type":"code","execution_count":17,"id":"a26a6b4d-5370-4a48-936a-84739ac0cc2f","metadata":{"id":"a26a6b4d-5370-4a48-936a-84739ac0cc2f","executionInfo":{"status":"ok","timestamp":1712316939285,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["# 用给定的处理器实例化数据整理器\n","data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"]},{"cell_type":"markdown","id":"80ecd4bc-01fd-4286-afe5-fe2639ae15a1","metadata":{"id":"80ecd4bc-01fd-4286-afe5-fe2639ae15a1"},"source":["## 模型准备\n","\n","### 加载预训练模型（int8 精度）\n","\n","使用 `int8 ` 精度加载预训练模型，进一步降低显存需求。"]},{"cell_type":"code","execution_count":18,"id":"f9fcb121-fa5c-4c30-8bdc-9ab08ab75427","metadata":{"id":"f9fcb121-fa5c-4c30-8bdc-9ab08ab75427","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316945561,"user_tz":-480,"elapsed":6282,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"9a538dcc-1b27-4090-be2d-f386ca04cffd"},"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"]}],"source":["from transformers import AutoModelForSpeechSeq2Seq\n","\n","model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")"]},{"cell_type":"code","execution_count":19,"id":"2cb016f1-e6e9-4fd8-9c8b-72fd23be92d3","metadata":{"id":"2cb016f1-e6e9-4fd8-9c8b-72fd23be92d3","executionInfo":{"status":"ok","timestamp":1712316945562,"user_tz":-480,"elapsed":4,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["# 设置模型配置中的forced_decoder_ids属性为None\n","model.config.forced_decoder_ids = None  # 这通常用于指定在解码（生成文本）过程中必须使用的特定token的ID，设置为None表示没有这样的强制要求\n","\n","# 设置模型配置中的suppress_tokens列表为空\n","model.config.suppress_tokens = []  # 这用于指定在生成过程中应被抑制（不生成）的token的列表，设置为空列表表示没有要抑制的token"]},{"cell_type":"markdown","id":"25ba1fa0-ea15-48d9-8c16-70df9f0b60b1","metadata":{"id":"25ba1fa0-ea15-48d9-8c16-70df9f0b60b1"},"source":["### PEFT 微调前的模型处理\n","\n","在使用 `peft` 训练 int8 模型之前，需要进行一些预处理：\n","- 将所有非 `int8` 精度模块转换为全精度（`fp32`）以保证稳定性\n","- 为输入嵌入层添加一个 `forward_hook`，以启用输入隐藏状态的梯度计算\n","- 启用梯度检查点以实现更高效的内存训练\n","\n","使用 `peft` 库预定义的工具函数 `prepare_model_for_int8_training`，便可自动完成以上模型处理工作。"]},{"cell_type":"code","source":["!pip install peft"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHtIQkw8EG5D","executionInfo":{"status":"ok","timestamp":1712316951054,"user_tz":-480,"elapsed":5495,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"31ba862e-cf14-4f29-d460-28585bdfc681"},"id":"kHtIQkw8EG5D","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.28.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":21,"id":"1ee34359-fe1b-48f1-827c-6a8ec4a53af7","metadata":{"id":"1ee34359-fe1b-48f1-827c-6a8ec4a53af7","executionInfo":{"status":"ok","timestamp":1712316951054,"user_tz":-480,"elapsed":30,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["from peft import prepare_model_for_kbit_training\n","\n","model = prepare_model_for_kbit_training(model)"]},{"cell_type":"markdown","id":"cb1212ae-c18c-459b-97a2-4b833c8414ae","metadata":{"id":"cb1212ae-c18c-459b-97a2-4b833c8414ae"},"source":["### LoRA Adapter 配置\n","\n","在 `peft` 中使用`LoRA`非常简捷，借助 `PeftModel`抽象，我们可以快速使用低秩适配器（LoRA）到任意模型。\n","\n","通过使用 `peft` 中的 `get_peft_model` 工具函数来实现。\n","\n","#### 关于 LoRA 超参数的说明：\n","```\n","MatMul(B,A) * Scaling\n","Scaling = LoRA_Alpha / Rank\n","```"]},{"cell_type":"code","execution_count":22,"id":"cdf6bc9c-6d2c-4dbf-b09e-a89cb1041c46","metadata":{"id":"cdf6bc9c-6d2c-4dbf-b09e-a89cb1041c46","executionInfo":{"status":"ok","timestamp":1712316951055,"user_tz":-480,"elapsed":30,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n","\n","# 创建一个LoraConfig对象，用于设置LoRA（Low-Rank Adaptation）的配置参数\n","config = LoraConfig(\n","    r=4,  # LoRA的秩，影响LoRA矩阵的大小\n","    lora_alpha=64,  # LoRA适应的比例因子\n","    # 指定将LoRA应用到的模型模块，通常是attention和全连接层的投影。\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    lora_dropout=0.05,  # 在LoRA模块中使用的dropout率\n","    bias=\"none\",  # 设置bias的使用方式，这里没有使用bias\n",")"]},{"cell_type":"markdown","id":"584652a6-cf07-49d3-a4ee-66f360441fc0","metadata":{"id":"584652a6-cf07-49d3-a4ee-66f360441fc0"},"source":["### 使用get_peft_model函数和给定的配置来获取一个PEFT模型"]},{"cell_type":"code","execution_count":23,"id":"7a8f9dc5-6e15-4f16-9ac5-e7492356fe88","metadata":{"id":"7a8f9dc5-6e15-4f16-9ac5-e7492356fe88","executionInfo":{"status":"ok","timestamp":1712316951055,"user_tz":-480,"elapsed":30,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["peft_model = get_peft_model(model, config)"]},{"cell_type":"code","execution_count":24,"id":"b74c7508-e6f4-42d8-8aaf-fe83c5977c35","metadata":{"id":"b74c7508-e6f4-42d8-8aaf-fe83c5977c35","outputId":"0abd4088-a963-45af-aadb-d50c0efed627","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316951055,"user_tz":-480,"elapsed":30,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 1,966,080 || all params: 1,545,271,040 || trainable%: 0.12723204856023188\n"]}],"source":["# 打印 LoRA 微调训练的模型参数\n","peft_model.print_trainable_parameters()"]},{"cell_type":"markdown","id":"1cc6b26a-3e54-4a46-9b36-a048b40a37d7","metadata":{"id":"1cc6b26a-3e54-4a46-9b36-a048b40a37d7"},"source":["## 模型训练\n","\n","#### Seq2SeqTrainingArguments 训练参数\n","\n","**关于设置训练步数和评估步数**\n","\n","基于 epochs 设置：\n","\n","```python\n","    num_train_epochs=3,  # 训练的总轮数\n","    evaluation_strategy=\"epoch\",  # 设置评估策略，这里是在每个epoch结束时进行评估\n","    warmup_steps=50,  # 在训练初期增加学习率的步数，有助于稳定训练\n","```\n","\n","基于 steps 设置：\n","\n","```python\n","    max_steps=100, # 训练总步数\n","    evaluation_strategy=\"steps\",\n","    eval_steps=25, # 评估步数\n","```"]},{"cell_type":"code","execution_count":25,"id":"11f259c8-dbcf-4a7f-bbb5-821ab104efee","metadata":{"id":"11f259c8-dbcf-4a7f-bbb5-821ab104efee","executionInfo":{"status":"ok","timestamp":1712316951055,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["from transformers import Seq2SeqTrainingArguments\n","model_dir = '/content/drive/MyDrive/model/my/whisper-large-v2-asr-int8'\n","batch_size = 128\n","# 设置序列到序列模型训练的参数\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_dir,  # 指定模型输出和保存的目录\n","    per_device_train_batch_size=batch_size,  # 每个设备上的训练批量大小\n","    learning_rate=1e-3,  # 学习率\n","    num_train_epochs=3,  # 训练的总轮数\n","    evaluation_strategy=\"epoch\",  # 设置评估策略，这里是在每个epoch结束时进行评估\n","    # warmup_steps=50,  # 在训练初期增加学习率的步数，有助于稳定训练\n","    # fp16=True,  # 启用混合精度训练，可以提高训练速度，同时减少内存使用\n","    per_device_eval_batch_size=batch_size,  # 每个设备上的评估批量大小\n","    generation_max_length=128,  # 生成任务的最大长度\n","    logging_steps=200,  # 指定日志记录的步骤，用于跟踪训练进度\n","    remove_unused_columns=False,  # 是否删除不使用的列，以减少数据处理开销\n","    label_names=[\"labels\"],  # 指定标签列的名称，用于训练过程中\n","    # evaluation_strategy=\"steps\",\n","    # eval_steps=25,\n",")"]},{"cell_type":"markdown","id":"c57ee183-b16f-4313-97f6-0df6c0f5f467","metadata":{"id":"c57ee183-b16f-4313-97f6-0df6c0f5f467"},"source":["### 实例化 Seq2SeqTrainer 训练器"]},{"cell_type":"code","execution_count":26,"id":"f8a52ed7-cae0-4aba-818e-87717430d908","metadata":{"id":"f8a52ed7-cae0-4aba-818e-87717430d908","outputId":"24f1f1d4-0dca-4533-c757-9cf550c0628a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316951055,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=peft_model,\n","    train_dataset=tokenized_common_voice[\"train\"],\n","    eval_dataset=tokenized_common_voice[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=processor.feature_extractor,\n",")\n","peft_model.config.use_cache = False"]},{"cell_type":"code","execution_count":27,"id":"6973bed7-8f53-4d55-966c-f037941e5ef3","metadata":{"id":"6973bed7-8f53-4d55-966c-f037941e5ef3","outputId":"c9542491-9406-4d5a-822b-40aee42179e4","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1712310009813,"user_tz":-480,"elapsed":6881262,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='499' max='681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [499/681 4:54:00 < 1:47:39, 0.03 it/s, Epoch 2.19/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.414400</td>\n","      <td>0.390665</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.301300</td>\n","      <td>0.381513</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='681' max='681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [681/681 6:48:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.414400</td>\n","      <td>0.390665</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.301300</td>\n","      <td>0.381513</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.249300</td>\n","      <td>0.384048</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=681, training_loss=0.3104845374691329, metrics={'train_runtime': 24570.7778, 'train_samples_per_second': 3.548, 'train_steps_per_second': 0.028, 'total_flos': 1.85319357677568e+20, 'train_loss': 0.3104845374691329, 'epoch': 3.0})"]},"metadata":{},"execution_count":27}],"source":["trainer.train()"]},{"cell_type":"markdown","id":"620992c3-64f5-48f9-8e66-fdc5f6a27427","metadata":{"id":"620992c3-64f5-48f9-8e66-fdc5f6a27427"},"source":["### 保存 LoRA 模型(Adapter)"]},{"cell_type":"code","execution_count":28,"id":"53310565-7313-46a7-acf1-215970fd4f8e","metadata":{"id":"53310565-7313-46a7-acf1-215970fd4f8e","executionInfo":{"status":"ok","timestamp":1712310010367,"user_tz":-480,"elapsed":555,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["trainer.save_model(model_dir)"]},{"cell_type":"code","execution_count":29,"id":"412785f2-f66f-492a-b01a-06ca81d9aed7","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"412785f2-f66f-492a-b01a-06ca81d9aed7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712310010368,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"42368585-814b-472c-c27c-76e126ba1e09"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModel(\n","  (base_model): LoraModel(\n","    (model): WhisperForConditionalGeneration(\n","      (model): WhisperModel(\n","        (encoder): WhisperEncoder(\n","          (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n","          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n","          (embed_positions): Embedding(1500, 1280)\n","          (layers): ModuleList(\n","            (0-31): 32 x WhisperEncoderLayer(\n","              (self_attn): WhisperSdpaAttention(\n","                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n","                (v_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (q_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","              )\n","              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (activation_fn): GELUActivation()\n","              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n","              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n","              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (decoder): WhisperDecoder(\n","          (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n","          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n","          (layers): ModuleList(\n","            (0-31): 32 x WhisperDecoderLayer(\n","              (self_attn): WhisperSdpaAttention(\n","                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n","                (v_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (q_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","              )\n","              (activation_fn): GELUActivation()\n","              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (encoder_attn): WhisperSdpaAttention(\n","                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n","                (v_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (q_proj): lora.Linear8bitLt(\n","                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","                  (lora_dropout): ModuleDict(\n","                    (default): Dropout(p=0.05, inplace=False)\n","                  )\n","                  (lora_A): ModuleDict(\n","                    (default): Linear(in_features=1280, out_features=4, bias=False)\n","                  )\n","                  (lora_B): ModuleDict(\n","                    (default): Linear(in_features=4, out_features=1280, bias=False)\n","                  )\n","                  (lora_embedding_A): ParameterDict()\n","                  (lora_embedding_B): ParameterDict()\n","                )\n","                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n","              )\n","              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n","              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n","              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":29}],"source":["peft_model.eval()"]},{"cell_type":"code","source":["# from google.colab import runtime\n","# runtime.unassign()"],"metadata":{"id":"dMqBViHBDTf_"},"id":"dMqBViHBDTf_","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"dcfe9611-eee5-462f-8cb8-fed86eec76e0","metadata":{"id":"dcfe9611-eee5-462f-8cb8-fed86eec76e0"},"source":["## 模型推理（可能需要重启 Notebook）\n","\n","**再次加载模型会额外占用显存，如果显存已经达到上限，建议重启 Notebook 后再进行以下操作**\n"]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"nH-0ksz0JCR6","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1712313167357,"user_tz":-480,"elapsed":1954602,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"0d2eac74-8bf1-4749-b7bf-95d268313866"},"id":"nH-0ksz0JCR6","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='83' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [83/83 31:55]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.3840476870536804,\n"," 'eval_runtime': 1953.9802,\n"," 'eval_samples_per_second': 5.415,\n"," 'eval_steps_per_second': 0.042,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ia0N5Iiq4ID5"},"id":"ia0N5Iiq4ID5"},{"cell_type":"code","execution_count":27,"id":"bd2890f5-2eb9-493d-b43b-266fb12c6ac6","metadata":{"id":"bd2890f5-2eb9-493d-b43b-266fb12c6ac6","executionInfo":{"status":"ok","timestamp":1712316036221,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["model_dir = \"/content/drive/MyDrive/model/my/whisper-large-v2-asr-int8\"\n","\n","language = \"Chinese (China)\"\n","language_abbr = \"zh-CN\"\n","language_decode = \"chinese\"\n","task = \"transcribe\""]},{"cell_type":"markdown","id":"d5ad8bc8-420b-4a98-b83f-08303693221b","metadata":{"id":"d5ad8bc8-420b-4a98-b83f-08303693221b"},"source":["\n","### 使用 `PeftModel` 加载 LoRA 微调后 Whisper 模型\n","\n","使用 `PeftConfig` 加载 LoRA Adapter 配置参数，使用 `PeftModel` 加载微调后 Whisper 模型"]},{"cell_type":"code","execution_count":28,"id":"9d7f3af5-af01-4c26-80e9-976686983178","metadata":{"id":"9d7f3af5-af01-4c26-80e9-976686983178","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316040306,"user_tz":-480,"elapsed":4091,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"74897c35-2098-4db1-f84b-3ae7a6bbc248"},"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"]}],"source":["from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n","from peft import PeftConfig, PeftModel\n","\n","peft_config = PeftConfig.from_pretrained(model_dir)\n","\n","base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n","    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",")\n","\n","peft_model = PeftModel.from_pretrained(base_model, model_dir)"]},{"cell_type":"code","execution_count":29,"id":"e3686334-d8d1-4782-834b-187aa684fb77","metadata":{"id":"e3686334-d8d1-4782-834b-187aa684fb77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712316043630,"user_tz":-480,"elapsed":3328,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"1331d78e-51fc-4a2b-8545-3d21346b22a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","feature_extractor = processor.feature_extractor"]},{"cell_type":"markdown","id":"c31e558c-0c7b-445c-8210-52bd04fc0dd7","metadata":{"id":"c31e558c-0c7b-445c-8210-52bd04fc0dd7"},"source":["### 使用 Pipeline API 部署微调后 Whisper 实现中文语音识别任务"]},{"cell_type":"code","execution_count":36,"id":"18181692-a143-44ee-b56c-e754d308e0ec","metadata":{"id":"18181692-a143-44ee-b56c-e754d308e0ec","executionInfo":{"status":"ok","timestamp":1712313369466,"user_tz":-480,"elapsed":654,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["test_audio = \"/content/drive/MyDrive/Colab Notebooks/geektime-llm/peft/data/audio/test_zh.flac\""]},{"cell_type":"code","execution_count":37,"id":"9d494647-082c-4e48-9486-7945618ae679","metadata":{"id":"9d494647-082c-4e48-9486-7945618ae679","executionInfo":{"status":"ok","timestamp":1712313370563,"user_tz":-480,"elapsed":1099,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[],"source":["from transformers import AutomaticSpeechRecognitionPipeline\n","\n","pipeline = AutomaticSpeechRecognitionPipeline(model=peft_model, tokenizer=tokenizer, feature_extractor=feature_extractor)\n","\n","forced_decoder_ids = processor.get_decoder_prompt_ids(language=language_decode, task=task)"]},{"cell_type":"code","execution_count":38,"id":"90da1707-9054-416f-b0b6-a6203f8d3285","metadata":{"id":"90da1707-9054-416f-b0b6-a6203f8d3285","outputId":"d52077c2-47b3-4884-9fe7-bc3bed36b871","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712313382355,"user_tz":-480,"elapsed":11794,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"]}],"source":["import torch\n","\n","with torch.cuda.amp.autocast():\n","    text = pipeline(test_audio, max_new_tokens=255)[\"text\"]"]},{"cell_type":"code","execution_count":39,"id":"89f49787-6ab4-4bc1-91b8-a1c104c9feaf","metadata":{"id":"89f49787-6ab4-4bc1-91b8-a1c104c9feaf","outputId":"e446df1c-f437-4af0-f3da-cc7984425cbe","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1712313382356,"user_tz":-480,"elapsed":30,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'这是一段测试用于Whisper Large V2模型的自动语音识别测试。'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}],"source":["text"]},{"cell_type":"markdown","id":"0285dd19-229e-4241-b680-71e25ab51dde","metadata":{"id":"0285dd19-229e-4241-b680-71e25ab51dde"},"source":["## Homework\n","\n","1. 使用完整的数据集训练，对比 Train Loss 和 Validation Loss 变化。训练完成后，使用测试集进行模型评估.\n","2. [Optional]使用其他语种（如：德语、法语等）的数据集进行微调训练，并进行模型评估模型评估。"]},{"cell_type":"code","source":["language = \"Chinese (China)\"\n","language_abbr = \"zh-CN\"\n","task = \"transcribe\"\n","dataset_name = \"mozilla-foundation/common_voice_11_0\"\n","\n","batch_size=16"],"metadata":{"id":"IH6JlsrnDner","executionInfo":{"status":"ok","timestamp":1712317239838,"user_tz":-480,"elapsed":540,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"IH6JlsrnDner","execution_count":36,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n","from peft import PeftConfig, PeftModel\n","\n","peft_config = PeftConfig.from_pretrained(model_dir)\n","\n","base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n","    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",")\n","base_model.requires_grad_(False)\n","\n","peft_model = PeftModel.from_pretrained(base_model, model_dir)\n","peft_model.eval()\n","\n","tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n","feature_extractor = processor.feature_extractor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4T6A66FKDysM","executionInfo":{"status":"ok","timestamp":1712317253212,"user_tz":-480,"elapsed":9433,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"d1ae9f25-ffe5-417d-9282-af7e3bf1a5ae"},"id":"4T6A66FKDysM","execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict, Audio\n","\n","common_voice = DatasetDict()\n","common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\", trust_remote_code=True)\n","common_voice = common_voice.remove_columns(\n","    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",")\n","common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"],"metadata":{"id":"2Kd6peJq2EB8","executionInfo":{"status":"ok","timestamp":1712317287410,"user_tz":-480,"elapsed":5918,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"2Kd6peJq2EB8","execution_count":38,"outputs":[]},{"cell_type":"code","source":["def prepare_dataset(batch):\n","    audio = batch[\"audio\"]\n","    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n","    return batch"],"metadata":{"id":"rTLUcWVb3RfL","executionInfo":{"status":"ok","timestamp":1712317287410,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"rTLUcWVb3RfL","execution_count":39,"outputs":[]},{"cell_type":"code","source":["small_common_voice = DatasetDict()\n","\n","small_common_voice[\"test\"] = common_voice[\"test\"].shuffle(seed=16)"],"metadata":{"id":"NVZ9Qfr4EHK6","executionInfo":{"status":"ok","timestamp":1712317310631,"user_tz":-480,"elapsed":4,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"NVZ9Qfr4EHK6","execution_count":40,"outputs":[]},{"cell_type":"code","source":["tokenized_common_voice = small_common_voice.map(prepare_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["aa4969e6792a4e5a9f50c620b18a7523","eac39c2d8404408db9c1eb67891d315b","d7ffaebb633e47bd9b6fdead1aee2e03","ea2d7878088e4fecae8eab60a12040ff","5e70a458dcbe4a1d8085b4fffbb0e13f","365610240a6a4f81881abf3a274d3669","e868a9ccdefc47c8b00ccddf035681f4","48cc226ff48845bda9b4dbba01c9e062","cc711e82774142fcb2fbbd73175e9a3f","d4d93795fa214b2a95f0adce32616c4b","07d8a0ab341d462f83f3632acc8e8f90"]},"id":"pZOUeEdGEKX5","executionInfo":{"status":"ok","timestamp":1712318476727,"user_tz":-480,"elapsed":1162463,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"c8531738-8ada-4141-e06b-677f9f03c7bd"},"id":"pZOUeEdGEKX5","execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10581 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa4969e6792a4e5a9f50c620b18a7523"}},"metadata":{}}]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"fIGFKAUl8beT","executionInfo":{"status":"ok","timestamp":1712318482782,"user_tz":-480,"elapsed":628,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"fIGFKAUl8beT","execution_count":43,"outputs":[]},{"cell_type":"code","source":["!pip install evaluate\n","!pip install jiwer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nPeVFIV3zP2","executionInfo":{"status":"ok","timestamp":1712318494594,"user_tz":-480,"elapsed":10639,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"8965acae-e192-452a-ff25-153c05cf9759"},"id":"9nPeVFIV3zP2","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.7.0)\n"]}]},{"cell_type":"code","source":["import evaluate\n","\n","# 词错误率（WER）是评估ASR模型常用的指标。从 Evaluate 加载 WER 指标\n","metric = evaluate.load(\"wer\")"],"metadata":{"id":"bpc7Q2cJ3jiy","executionInfo":{"status":"ok","timestamp":1712318495357,"user_tz":-480,"elapsed":767,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"bpc7Q2cJ3jiy","execution_count":45,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import numpy as np\n","import gc\n","\n","\n","eval_dataloader = DataLoader(tokenized_common_voice[\"test\"], batch_size=batch_size, collate_fn=data_collator)"],"metadata":{"id":"YMO8oMIA3pNv","executionInfo":{"status":"ok","timestamp":1712318495358,"user_tz":-480,"elapsed":4,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}}},"id":"YMO8oMIA3pNv","execution_count":46,"outputs":[]},{"cell_type":"code","source":["# 遍历评估数据加载器中的所有批次\n","for step, batch in enumerate(tqdm(eval_dataloader)):\n","    # 使用自动混合精度来加速计算，并减少显存使用\n","    with torch.cuda.amp.autocast():\n","        # 不计算梯度，以节省计算资源，仅用于推理和评估\n","        with torch.no_grad():\n","            # 生成预测的标记(tokens)，这里使用模型的generate函数进行文本生成\n","            generated_tokens = (\n","                peft_model.generate(\n","                    input_features=batch[\"input_features\"].to(\"cuda\"),  # 将输入特征移动到GPU上\n","                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),  # 提供解码器的初始输入\n","                    max_new_tokens=255,  # 设置生成的最大新标记数量\n","                    language='chinese',\n","                )\n","                .cpu()  # 将生成的标记移回CPU\n","                .numpy()  # 转换为NumPy数组以便进一步处理\n","            )\n","            # 获取批次中的标签，并将其移回CPU\n","            labels = batch[\"labels\"].cpu().numpy()\n","            # 将标签中的-100替换为填充标记的ID，-100通常用于忽略计算损失的标记\n","            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","            # 使用分词器解码生成的标记和标签，以获得可读的文本\n","            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","            # 将预测和参考添加到评估指标中，用于后续的性能评估\n","            metric.add_batch(\n","                predictions=decoded_preds,\n","                references=decoded_labels,\n","            )\n","    # 删除不再需要的变量以释放内存\n","    del generated_tokens, labels, batch\n","    # 手动触发垃圾收集，进一步清理内存\n","    gc.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myqGG-7m3tBx","executionInfo":{"status":"ok","timestamp":1712326973966,"user_tz":-480,"elapsed":7954477,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"f36c294d-cb37-4789-ded9-43c8d8674e84"},"id":"myqGG-7m3tBx","execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/662 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:1286: FutureWarning: You have provided `decoder_input_ids` which will overwrite the `init_tokens` [50258, 50260, 50359, 50363]. This might lead to unexpected behavior. Passing `decoder_input_ids` is deprecated and will be removed in v4.39. Consider passing `prompt_ids` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","100%|██████████| 662/662 [2:19:28<00:00, 12.64s/it]\n"]}]},{"cell_type":"code","source":["# 计算词错误率（WER）指标，并将结果转换为百分比形式\n","wer = 100 * metric.compute()\n","\n","# 打印词错误率，f\"{wer=}\"是一种格式化字符串的简洁写法，它会展示变量名和值\n","print(f\"{wer=}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0uk7lAR3wS3","executionInfo":{"status":"ok","timestamp":1712326973967,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yeran Wu","userId":"17804197138441176585"}},"outputId":"f7d961b2-a901-49b4-8389-ec45a2d9641a"},"id":"F0uk7lAR3wS3","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["wer=56.18975618975619%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"izd_22pw8fFZ"},"id":"izd_22pw8fFZ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["dcfe9611-eee5-462f-8cb8-fed86eec76e0","d5ad8bc8-420b-4a98-b83f-08303693221b","c31e558c-0c7b-445c-8210-52bd04fc0dd7"],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa4969e6792a4e5a9f50c620b18a7523":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eac39c2d8404408db9c1eb67891d315b","IPY_MODEL_d7ffaebb633e47bd9b6fdead1aee2e03","IPY_MODEL_ea2d7878088e4fecae8eab60a12040ff"],"layout":"IPY_MODEL_5e70a458dcbe4a1d8085b4fffbb0e13f"}},"eac39c2d8404408db9c1eb67891d315b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_365610240a6a4f81881abf3a274d3669","placeholder":"​","style":"IPY_MODEL_e868a9ccdefc47c8b00ccddf035681f4","value":"Map: 100%"}},"d7ffaebb633e47bd9b6fdead1aee2e03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48cc226ff48845bda9b4dbba01c9e062","max":10581,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc711e82774142fcb2fbbd73175e9a3f","value":10581}},"ea2d7878088e4fecae8eab60a12040ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4d93795fa214b2a95f0adce32616c4b","placeholder":"​","style":"IPY_MODEL_07d8a0ab341d462f83f3632acc8e8f90","value":" 10581/10581 [19:21&lt;00:00,  2.33s/ examples]"}},"5e70a458dcbe4a1d8085b4fffbb0e13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"365610240a6a4f81881abf3a274d3669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e868a9ccdefc47c8b00ccddf035681f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48cc226ff48845bda9b4dbba01c9e062":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc711e82774142fcb2fbbd73175e9a3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4d93795fa214b2a95f0adce32616c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d8a0ab341d462f83f3632acc8e8f90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}