{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/careywyr/geektime-llm/blob/main/homework/week2/fine_tune_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c6730f-5d76-450b-9788-ec883d024f57",
      "metadata": {
        "id": "90c6730f-5d76-450b-9788-ec883d024f57"
      },
      "source": [
        "# Hugging Face Transformers 微调训练入门\n",
        "\n",
        "本示例将介绍基于 Transformers 实现模型微调训练的主要流程，包括：\n",
        "- 数据集下载\n",
        "- 数据预处理\n",
        "- 训练超参数配置\n",
        "- 训练评估指标设置\n",
        "- 训练器基本介绍\n",
        "- 实战训练\n",
        "- 模型保存"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe",
      "metadata": {
        "id": "aa0b1e12-1921-4438-8d5d-9760a629dcfe"
      },
      "source": [
        "## YelpReviewFull 数据集\n",
        "\n",
        "**Hugging Face 数据集：[ YelpReviewFull ](https://huggingface.co/datasets/yelp_review_full)**\n",
        "\n",
        "### 数据集摘要\n",
        "\n",
        "Yelp评论数据集包括来自Yelp的评论。它是从Yelp Dataset Challenge 2015数据中提取的。\n",
        "\n",
        "### 支持的任务和排行榜\n",
        "文本分类、情感分类：该数据集主要用于文本分类：给定文本，预测情感。\n",
        "\n",
        "### 语言\n",
        "这些评论主要以英语编写。\n",
        "\n",
        "### 数据集结构\n",
        "\n",
        "#### 数据实例\n",
        "一个典型的数据点包括文本和相应的标签。\n",
        "\n",
        "来自YelpReviewFull测试集的示例如下：\n",
        "\n",
        "```json\n",
        "{\n",
        "    'label': 0,\n",
        "    'text': 'I got \\'new\\' tires from them and within two weeks got a flat. I took my car to a local mechanic to see if i could get the hole patched, but they said the reason I had a flat was because the previous patch had blown - WAIT, WHAT? I just got the tire and never needed to have it patched? This was supposed to be a new tire. \\\\nI took the tire over to Flynn\\'s and they told me that someone punctured my tire, then tried to patch it. So there are resentful tire slashers? I find that very unlikely. After arguing with the guy and telling him that his logic was far fetched he said he\\'d give me a new tire \\\\\"this time\\\\\". \\\\nI will never go back to Flynn\\'s b/c of the way this guy treated me and the simple fact that they gave me a used tire!'\n",
        "}\n",
        "```\n",
        "\n",
        "#### 数据字段\n",
        "\n",
        "- 'text': 评论文本使用双引号（\"）转义，任何内部双引号都通过2个双引号（\"\"）转义。换行符使用反斜杠后跟一个 \"n\" 字符转义，即 \"\\n\"。\n",
        "- 'label': 对应于评论的分数（介于1和5之间）。\n",
        "\n",
        "#### 数据拆分\n",
        "\n",
        "Yelp评论完整星级数据集是通过随机选取每个1到5星评论的130,000个训练样本和10,000个测试样本构建的。总共有650,000个训练样本和50,000个测试样本。\n",
        "\n",
        "## 下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTbCrTbmo1ts",
        "outputId": "df7b38ae-8779-4736-9a4c-0be267d3b179"
      },
      "id": "rTbCrTbmo1ts",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers[torch]\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQnkr8uNpJA7",
        "outputId": "70ffb905-6093-48c6-e88b-9206aa6a60ef"
      },
      "id": "oQnkr8uNpJA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4",
      "metadata": {
        "id": "bbf72d6c-7ea5-4ee1-969a-c5060b9cb2d4"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"yelp_review_full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6fc806-1395-42dd-8121-a6e98a95cf01",
        "outputId": "c9ccf999-c577-42c3-ec16-024c9c9884e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 650000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c94ad529-1604-48bd-8c8d-aa2f3bca6200",
        "outputId": "aec3f4f9-51bb-4c6e-afd8-7d4191edc846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'text': \"As far as Starbucks go, this is a pretty nice one.  The baristas are friendly and while I was here, a lot of regulars must have come in, because they bantered away with almost everyone.  The bathroom was clean and well maintained and the trash wasn't overflowing in the canisters around the store.  The pastries looked fresh, but I didn't partake.  The noise level was also at a nice working level - not too loud, music just barely audible.\\\\n\\\\nI do wish there was more seating.  It is nice that this location has a counter at the end of the bar for sole workers, but it doesn't replace more tables.  I'm sure this isn't as much of a problem in the summer when there's the space outside.\\\\n\\\\nThere was a treat receipt promo going on, but the barista didn't tell me about it, which I found odd.  Usually when they have promos like that going on, they ask everyone if they want their receipt to come back later in the day to claim whatever the offer is.  Today it was one of their new pastries for $1, I know in the summer they do $2 grande iced drinks with that morning's receipt.\\\\n\\\\nOverall, nice working or socializing environment.  Very friendly and inviting.  It's what I've come to expect from Starbucks, so points for consistency.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset[\"train\"][111]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d",
      "metadata": {
        "id": "6dc45997-e391-456f-b0b9-d3193b0f6a9d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622",
      "metadata": {
        "id": "9e2ecebb-d5d1-456d-967c-842a79fdd622"
      },
      "outputs": [],
      "source": [
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af560b6-7d21-499e-9b82-114be371a98a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "1af560b6-7d21-499e-9b82-114be371a98a",
        "outputId": "6ce3ab2e-62f0-45d1-b8f7-e41e9ea65a85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2 star</td>\n",
              "      <td>I didn't see what all the rage was about. This was just an average cab ride in a pretty junky car.  The back seat was fairly clean but the windshield had a huge crack across it and the front console hadn't been cleaned in a long time. My driver was a nice enough guy but the company presents itself as having more of a polished driver and this driver was dressed overly casual -- like your basic cabbie. I was quoted the flat rate to Sky Harbor and thought I'd be greeted with coffee and donuts like the profile on here says. When I entered the cab, no coffee and no donuts. Not even a mention of them. Is it just a marketing ploy? Widows were partially down during the entire trip making it very difficult to hear anything coming out of the driver's mouth. Again, I have no trouble with the driver but there is nothing above average about this service. While making the reservation was easy and the driver was on time, there was nothing that set this company apart from others. I was disappointed. Will not repeat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3 stars</td>\n",
              "      <td>C'Mon, it is Dillard's. Good stuff, not great. Quality stuff at a good price. Stylish without having to schlep on over to the foo foo places of the Fashion Show. The standard of suburban outposts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2 star</td>\n",
              "      <td>This was a second trip to this restaurant, but compared to the first visit......it was not good. Service was slow. Food was disappointing. Took 5 min. To get a fork to eat my meal. The duck was ok, but boring. Served with a medallion potato that could have come from mcdonalds. 2 of the meals were cold and had to be redone. The skirt steak arrived as the rest of us were finishing. And the meat tasted \\\"old\\\"..... Not fresh. We were there at 6 and it wasn't crowded, but their excuse was that they were still catching up from an earlier rush. Lame.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5 stars</td>\n",
              "      <td>I have been here three times now and every single visit has been amazing! I heard about this place from a coworker and decided to give it a shot. It's very modern looking inside the restaurant and has a very fun vibe to it. The wait staff is very attentive and knowledgable. So looking at the menu, they have a very unique list of dishes. The first visit I ordered the New Mexican green chili cheese burger. Now when it comes to any type of chili, ESPECIALLY New Mexican chili I am super picky. All my family is from Albuquerque, and my grandfather actually grows his own red and green chili, so I know authentic New Mexican chili. DW Bistro did not disappoint and had the real deal. I was in heaven! Getting to eat good green chili is something I look forward everytime I go visit my family, and now I have a place to go to while I'm not over there. I ordered my burger rare because most places over cook their meat. DW on the other hand made it true rare, which not to their fault, was a little too rare lol. The burger was nothing short of amazing though. \\nI've also tried their flautas, enchiladas (special of the day at the time), and the Jamacian chicken curry on couscous. \\nNow let's talk drinks. I'm not a fan of bloody marys, but due to the fact that they add two strips of bacon and a whole pickle as garnishment, I might order it next time. I usually stick to the Jamacian mojito, and boy do they make it strong. They also have a wide assortment of beers from the Caribbean. \\nI keep hearing about their brunch on Sundays, but going anytime is a good time. My only negative comment about this place is the ginger candy they give you with the bill. Yuck! Lol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 stars</td>\n",
              "      <td>I highly recommend this restaurant, especially for their happy hour! Totally worth it and the food is excellent! My favorite are the Seared Blackened Ahi which tasted superb and the Black Mussels. I tried the escargot, bruschetta and catfish bites as well and they were all tasted wonderful! I highly recommend to try this place as I found it's the best restaurant for happy hours and dinner! Great choice!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2 star</td>\n",
              "      <td>I finally got around to trying Bar-B-Q King.  The weather was pretty nice so it was a good day for a drive in.  I always try to keep an open mind when eating at a place for the first time which can be tough after reading reviews about the place.  I ordered BBQ plate which comes with 2 sides.  I got fries and slaw.  My visit was on a Saturday between noon and 1 pm.  The place seemed pretty busy with about 50% of the stalls occupied.  It took a little while to get my food, but not so long as to start thinking, \\\"where is my food.\\\"  The server dropped my tray off and quickly moved on the the next car without getting my money.  Odd, but probably the most efficient.  The pork was minced with sauce on it.  The slaw was also minced rather than being shredded.  There was also a sandwich bun along with the fries.  I was able to get some pork without sauce to try first.  The pork was moist and tender, but very bland.  I then tried some of the pork with the sauce and the sauce was bland too.  There was no smoke flavor at all.  The fries were good, fluffy on the inside, but not quite crisp enough.  The slaw was crunchy and fresh, but it too was bland.  I don't really care about the sauce.  Tastes vary and some like it spicier than others.  But the pork although being tender and moist was disappointing.  Overall it wasn't a bad meal, but it wasn't good either.  Again there are better places to go for much better BBQ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1 star</td>\n",
              "      <td>Called twice to request visit to review work to be done and estimate - never returned calls.  Takes more than skill with tools to be a good service provider.  It also takes being courteous and responsive to customer calls.  Moving on to next one on Yelp list...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5 stars</td>\n",
              "      <td>Bravo to this wonderful florist for flawless customer service. My wonderful boyfriend planned to have flowers delivered to my job on my birthday from 1800flowers. When he discovered they were never delivered they told him I'd get them the following day (not my birthday). He was extremely upset and called Nectar close to their closing time and they were more than happy to throw together a beautiful arrangement for him AND deliver them. Nectar to the birthday rescue my boyfriend was EXTREMELY pleased and my last min arrangement was filled with beautiful poppies and hydrangea ! Thank you !!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3 stars</td>\n",
              "      <td>The restaurant is beautiful.  The staff is super friendly.  The food was ok.  I ordered the mousaka entree and it was dry.  The baklava was hard and all I could taste was cinnamon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1 star</td>\n",
              "      <td>Went here for breakfest during the ironman race. Not sure if they regularrly serve breakfest here or not but the breakfest during the ironman was disgusting to say the least. My sister ordered French Toast and it looked like a plate of snot. The batter was runnie and quite obviously under cooked. My dad had the ironman skillet which was so small it wouldn't even make the childrens menu in chicago. The tomato juice wasn't tomato juice but a bar mixer used to make bloody mary's. All and all a big disappointment for breakfest, maybe the dinners are better but the breakfest was just aweful.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62",
      "metadata": {
        "id": "c9df7cd0-23cd-458f-b2b5-f025c3b9fe62"
      },
      "source": [
        "## 预处理数据\n",
        "\n",
        "下载数据集到本地后，使用 Tokenizer 来处理文本，对于长度不等的输入数据，可以使用填充（padding）和截断（truncation）策略来处理。\n",
        "\n",
        "Datasets 的 `map` 方法，支持一次性在整个数据集上应用预处理函数。\n",
        "\n",
        "下面使用填充到最大长度的策略，处理整个数据集："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38",
      "metadata": {
        "id": "8bf2b342-e1dd-4ab6-ad57-28eb2513ae38"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "47a415a8-cd15-4a8c-851b-9b4740ef8271",
        "outputId": "ac4deb0e-b078-4344-c8da-4ac05e24d0f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 stars</td>\n",
              "      <td>My friend and I were looking for a place to catch up so I could hear all about her recent adventures to Europe. There are some cool deals around Pittsburgh on Tuesday nights, but I had been wanting to try Verde for a while and the 20% off Taco Tuesday was definitely a draw.\\n\\nWe started with the chips, salsa, and guacamole. Everything was delicious - the chips were still warm, the guac was nice and chunky, and the pico de gallo was a great balance of acidity and tang. I think we could have done with more pico, but that's minor. I had the pollo tacos and pescado tacos and both were great. The pescado was spicy and I had never seen carrots on a taco before, but it worked. The pollo taco had moist meat and a deep flavor. My friend had the camarones taco and the carnitas taco and had glowing things to say about both. I can't really comment on the drinks, since we both just had cans of Tacate, but next time I'm there and don't have to drive, I'll be hitting up a margarita. We both had Mexican ice cream for dessert and it was super creamy and rich.\\n\\nOur server was great - attentive, friendly, and able to recommend some of her favorites to us. I was nervous to go after reading some of the older comments on Yelp, but I would DEFINITELY go back again.The only thing I would caution against is going when it is very very hot. It was a 90 degree day and there was some air circulating, but I don't think there was any a/c on. I was pretty sweaty by the end of the meal, and so was my friend. I can't believe I'm writing about sweat in a Yelp review...but there it is. Anyway, Verde: you should go.</td>\n",
              "      <td>[101, 1422, 1910, 1105, 146, 1127, 1702, 1111, 170, 1282, 1106, 3963, 1146, 1177, 146, 1180, 2100, 1155, 1164, 1123, 2793, 12108, 1106, 1980, 119, 1247, 1132, 1199, 4348, 8927, 1213, 5610, 1113, 9667, 6823, 117, 1133, 146, 1125, 1151, 5277, 1106, 2222, 17832, 1111, 170, 1229, 1105, 1103, 1406, 110, 1228, 22515, 2528, 9667, 1108, 5397, 170, 3282, 119, 165, 183, 165, 183, 2924, 1162, 1408, 1114, 1103, 13228, 117, 21718, 3447, 1161, 117, 1105, 176, 6718, 24282, 9016, 119, 5268, 1108, 13108, 118, 1103, 13228, 1127, 1253, 3258, 117, 1103, 176, 6718, 1665, 1108, 3505, 1105, 24384, 1183, ...]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b",
      "metadata": {
        "id": "1c33d153-f729-4f04-972c-a764c1cbbb8b"
      },
      "source": [
        "### 数据抽样\n",
        "\n",
        "使用 1000 个数据样本，在 BERT 上演示小规模训练（基于 Pytorch Trainer）\n",
        "\n",
        "`shuffle()`函数会随机重新排列列的值。如果您希望对用于洗牌数据集的算法有更多控制，可以在此函数中指定generator参数来使用不同的numpy.random.Generator。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17317d8-3c6a-467f-843d-87491f600db1",
      "metadata": {
        "id": "a17317d8-3c6a-467f-843d-87491f600db1"
      },
      "outputs": [],
      "source": [
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec",
      "metadata": {
        "id": "d3b65d63-2d3a-4a56-bc31-6e88a29e9dec"
      },
      "source": [
        "## 微调训练配置\n",
        "\n",
        "### 加载 BERT 模型\n",
        "\n",
        "警告通知我们正在丢弃一些权重（`vocab_transform` 和 `vocab_layer_norm` 层），并随机初始化其他一些权重（`pre_classifier` 和 `classifier` 层）。在微调模型情况下是绝对正常的，因为我们正在删除用于预训练模型的掩码语言建模任务的头部，并用一个新的头部替换它，对于这个新头部，我们没有预训练的权重，所以库会警告我们在用它进行推理之前应该对这个模型进行微调，而这正是我们要做的事情。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d2af4df-abd4-4a4b-94b6-b0e7375304ed",
        "outputId": "73329a9e-6a36-4d3f-de53-fbe5a94e3251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44014df-b52c-4c72-9e9f-54424725a473",
      "metadata": {
        "id": "b44014df-b52c-4c72-9e9f-54424725a473"
      },
      "source": [
        "### 训练超参数（TrainingArguments）\n",
        "\n",
        "完整配置参数与默认值：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments\n",
        "\n",
        "源代码定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161\n",
        "\n",
        "**最重要配置：模型权重保存路径(output_dir)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888",
      "metadata": {
        "id": "98c01d5c-de72-4ff0-b11d-e07ac5346888"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "model_dir = \"/content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp\"\n",
        "\n",
        "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
        "training_args = TrainingArguments(output_dir=model_dir,\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  num_train_epochs=5,\n",
        "                                  logging_steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ce03480-3aaa-48ea-a0c6-a177b8d8e34f",
        "outputId": "2bf01924-7ac9-421e-c1f0-b13bbdce36aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/runs/Mar23_12-23-12_6ccd0923d36d,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=5,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=/content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 完整的超参数配置\n",
        "print(training_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebd3365-d359-4ab4-a300-4717590cc240",
      "metadata": {
        "id": "7ebd3365-d359-4ab4-a300-4717590cc240"
      },
      "source": [
        "### 训练过程中的指标评估（Evaluate)\n",
        "\n",
        "**[Hugging Face Evaluate 库](https://huggingface.co/docs/evaluate/index)** 支持使用一行代码，获得数十种不同领域（自然语言处理、计算机视觉、强化学习等）的评估方法。 当前支持 **完整评估指标：https://huggingface.co/evaluate-metric**\n",
        "\n",
        "训练器（Trainer）在训练过程中不会自动评估模型性能。因此，我们需要向训练器传递一个函数来计算和报告指标。\n",
        "\n",
        "Evaluate库提供了一个简单的准确率函数，您可以使用`evaluate.load`函数加载"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5_hWCZFid7r",
        "outputId": "edcef585-5578-46d8-d1f5-cafb588f0aa4"
      },
      "id": "v5_hWCZFid7r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f",
      "metadata": {
        "id": "2a8ef138-5bf2-41e5-8c68-df8e11f4e98f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254",
      "metadata": {
        "id": "70d406c0-56d0-4a54-9c6c-e126ab7f5254"
      },
      "source": [
        "\n",
        "接着，调用 `compute` 函数来计算预测的准确率。\n",
        "\n",
        "在将预测传递给 compute 函数之前，我们需要将 logits 转换为预测值（**所有Transformers 模型都返回 logits**）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19",
      "metadata": {
        "id": "f46d2e59-1ebf-43d2-bc86-6b57a4d24d19"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1",
      "metadata": {
        "id": "e2feba67-9ca9-4793-9a15-3eaa426df2a1"
      },
      "source": [
        "#### 训练过程指标监控\n",
        "\n",
        "通常，为了监控训练过程中的评估指标变化，我们可以在`TrainingArguments`指定`evaluation_strategy`参数，以便在 epoch 结束时报告评估指标。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1",
      "metadata": {
        "id": "afaaee18-4986-4e39-8ad9-b8d413ab4cd1"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=model_dir,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  per_device_train_batch_size=32,\n",
        "                                  num_train_epochs=3,\n",
        "                                  logging_steps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12",
      "metadata": {
        "id": "d47d6981-e444-4c0f-a7cb-dd7f2ba8df12"
      },
      "source": [
        "## 开始训练\n",
        "\n",
        "### 实例化训练器（Trainer）\n",
        "\n",
        "`kernel version` 版本问题：暂不影响本示例代码运行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
      "metadata": {
        "id": "ca1d12ac-89dc-4c30-8282-f859724c0062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90020927-d5dd-4c86-9d30-1acecdbdcd56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157",
      "metadata": {
        "id": "a833e0db-1168-4a3c-8b75-bfdcef8c5157"
      },
      "source": [
        "## 使用 nvidia-smi 查看 GPU 使用\n",
        "\n",
        "为了实时查看GPU使用情况，可以使用 `watch` 指令实现轮询：`watch -n 1 nvidia-smi`:\n",
        "\n",
        "```shell\n",
        "Every 1.0s: nvidia-smi                                                   Wed Dec 20 14:37:41 2023\n",
        "\n",
        "Wed Dec 20 14:37:41 2023\n",
        "+---------------------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
        "|-----------------------------------------+----------------------+----------------------+\n",
        "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                                         |                      |               MIG M. |\n",
        "|=========================================+======================+======================|\n",
        "|   0  Tesla T4                       Off | 00000000:00:0D.0 Off |                    0 |\n",
        "| N/A   64C    P0              69W /  70W |   6665MiB / 15360MiB |     98%      Default |\n",
        "|                                         |                      |                  N/A |\n",
        "+-----------------------------------------+----------------------+----------------------+\n",
        "\n",
        "+---------------------------------------------------------------------------------------+\n",
        "| Processes:                                                                            |\n",
        "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
        "|        ID   ID                                                             Usage      |\n",
        "|=======================================================================================|\n",
        "|    0   N/A  N/A     18395      C   /root/miniconda3/bin/python                6660MiB |\n",
        "+---------------------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "accfe921-471d-481a-96da-c491cdebad0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "accfe921-471d-481a-96da-c491cdebad0c",
        "outputId": "57d4eb6b-6eb5-497a-8964-16b37b4a1cc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4120' max='60939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4120/60939 52:44 < 12:07:47, 1.30 it/s, Epoch 0.20/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-4000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60939' max='60939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60939/60939 12:41:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.773600</td>\n",
              "      <td>0.723138</td>\n",
              "      <td>0.680780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.654900</td>\n",
              "      <td>0.700844</td>\n",
              "      <td>0.693160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.577200</td>\n",
              "      <td>0.729505</td>\n",
              "      <td>0.695780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-4500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-5000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-5500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-6500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-7000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-7500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-8000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-8500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-9000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-9500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-10000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-10500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-11000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-11500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-12000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-12500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-13000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-13500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-14000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-14500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-15000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-15500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory /content/drive/MyDrive/model/my/bert-base-cased-finetune-yelp/checkpoint-16000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=60939, training_loss=0.6718601379844615, metrics={'train_runtime': 45686.9663, 'train_samples_per_second': 42.682, 'train_steps_per_second': 1.334, 'total_flos': 5.130803778048e+17, 'train_loss': 0.6718601379844615, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6d581099-37a4-4470-b051-1ada38554089",
      "metadata": {
        "id": "6d581099-37a4-4470-b051-1ada38554089"
      },
      "outputs": [],
      "source": [
        "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
      "metadata": {
        "id": "ffb47eab-1370-491e-8a84-6d5347a350b2",
        "outputId": "3876a833-8d0a-4c18-e4e6-8fe76f04b8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.7584921717643738,\n",
              " 'eval_accuracy': 0.691,\n",
              " 'eval_runtime': 8.5732,\n",
              " 'eval_samples_per_second': 116.642,\n",
              " 'eval_steps_per_second': 14.58,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "trainer.evaluate(small_test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52",
      "metadata": {
        "id": "27a55686-7c43-4ab8-a5cd-0e77f14c7c52"
      },
      "source": [
        "### 保存模型和训练状态\n",
        "\n",
        "- 使用 `trainer.save_model` 方法保存模型，后续可以通过 from_pretrained() 方法重新加载\n",
        "- 使用 `trainer.save_state` 方法保存训练状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41",
      "metadata": {
        "id": "ad0cbc14-9ef7-450f-a1a3-4f92b6486f41"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e30510-0536-49d4-8e1b-43fc25272bde",
      "metadata": {
        "id": "f6e30510-0536-49d4-8e1b-43fc25272bde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "badf5868-2847-439d-a73e-42d1cca67b5e",
      "metadata": {
        "id": "badf5868-2847-439d-a73e-42d1cca67b5e"
      },
      "outputs": [],
      "source": [
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9441ad-f65a-42b7-9016-4809c78285e9",
      "metadata": {
        "id": "8c9441ad-f65a-42b7-9016-4809c78285e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a",
      "metadata": {
        "id": "fd92e35d-fed7-4ff2-aa84-27b5e29b917a"
      },
      "outputs": [],
      "source": [
        "# trainer.model.save_pretrained(\"./\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61828934-01da-4fc3-9e75-8d754c25dfbc",
      "metadata": {
        "id": "61828934-01da-4fc3-9e75-8d754c25dfbc"
      },
      "source": [
        "## Homework: 使用完整的 YelpReviewFull 数据集训练，看 Acc 最高能到多少"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee2580a-7a5a-46ae-a28b-b41e9e838eb1",
      "metadata": {
        "id": "6ee2580a-7a5a-46ae-a28b-b41e9e838eb1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}