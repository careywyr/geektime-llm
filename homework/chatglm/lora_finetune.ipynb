{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/careywyr/geektime-llm/blob/main/homework/chatglm/lora_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
        "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
        "\n",
        "## 硬件需求\n",
        "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
        "内存：16GB\n",
        "RAM: 2.9 /16 GB\n",
        "GPU RAM: 15.5/16.0 GB"
      ],
      "metadata": {
        "collapsed": false,
        "id": "89b89f64d8f8053d"
      },
      "id": "89b89f64d8f8053d"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWJhoBIb289K",
        "outputId": "f905d952-876e-497d-8d48-0a272f29e843"
      },
      "id": "XWJhoBIb289K",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r '/content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHk5bTt5ufQ",
        "outputId": "8f0574be-34a3-438e-9abb-8933da3f0c6e"
      },
      "id": "9OHk5bTt5ufQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf>=4.25.3 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 3))\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/302.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.39.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (4.40.2)\n",
            "Requirement already satisfied: tokenizers>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 5)) (0.19.1)\n",
            "Collecting cpm_kernels>=1.0.11 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 6))\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (2.2.1+cu121)\n",
            "Collecting gradio>=4.26.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading gradio-4.31.0-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.2.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 9))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers>=2.4.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 10))\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.29.2 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 11))\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit>=1.33.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.110.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru~=0.7.2 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 14))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdtex2html>=1.3.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 15))\n",
            "  Downloading mdtex2html-1.3.0-py3-none-any.whl (13 kB)\n",
            "Collecting latex2mathml>=3.77.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 16))\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_client>=8.6.1 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.17.1 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 20))\n",
            "  Downloading openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zhipuai>=2.0.1 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 21))\n",
            "  Downloading zhipuai-2.0.1.20240429-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 22)) (2.7.1)\n",
            "Collecting sse-starlette>=2.0.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 23))\n",
            "  Downloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\n",
            "Collecting uvicorn>=0.29.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.16 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 25))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken>=0.6.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 26))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain>=0.1.16 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub>=0.1.15 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 31))\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Collecting arxiv>=2.1.0 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 32))\n",
            "  Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (4.2.2)\n",
            "Collecting ffmpy (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.2 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading gradio_client-0.16.2-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (6.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (9.4.0)\n",
            "Collecting pydub (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2.0.7)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.2->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers>=2.4.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers>=2.4.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.29.2->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (8.1.7)\n",
            "Collecting protobuf>=4.25.3 (from -r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 3))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (0.10.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.110.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.110.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.110.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.110.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mdtex2html>=1.3.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 15)) (3.6)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (5.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (24.0.1)\n",
            "Requirement already satisfied: traitlets>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (5.7.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.17.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.17.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 20)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.17.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 20)) (1.3.1)\n",
            "Collecting pyjwt<2.9.0,>=2.8.0 (from zhipuai>=2.0.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 21))\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 22)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 22)) (2.18.2)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.29.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 25)) (0.17.1+cu121)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub>=0.1.15->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 31))\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Collecting feedparser==6.0.10 (from arxiv>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 32))\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sgmllib3k (from feedparser==6.0.10->arxiv>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 32))\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.17.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 20)) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.110.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 13))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (4.2.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging>=20.0 (from transformers>=4.39.3->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 4))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter_client>=8.6.1->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30)) (3.0.3)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.29.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.29.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.29.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.29.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 24))\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers>=2.4.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 10)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers>=2.4.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 7)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.26.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 8)) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.33.0->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 12)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.1.16->-r /content/drive/MyDrive/Colab Notebooks/ChatGLM3/requirements.txt (line 30))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: ffmpy, sgmllib3k\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=4a7fa2cbdb31cfc807f7660ff510a5c911aedafb34ef0cf48ed17e38cc61f739\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=19369b8a69cd58c980f9ebce554f34140b39dd36cabce5db4cd11c99914ccb82\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built ffmpy sgmllib3k\n",
            "Installing collected packages: sgmllib3k, sentencepiece, pydub, ffmpy, cpm_kernels, websockets, watchdog, uvloop, ujson, types-requests, tomlkit, smmap, shellingham, semantic-version, ruff, python-multipart, python-dotenv, pyjwt, protobuf, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, loguru, latex2mathml, jsonpointer, httptools, h11, feedparser, dnspython, aiofiles, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mdtex2html, marshmallow, langchainhub, jupyter_client, jsonpatch, httpcore, gitdb, email_validator, arxiv, typer, sse-starlette, nvidia-cusolver-cu12, langsmith, httpx, gitpython, dataclasses-json, zhipuai, openai, langchain-core, gradio-client, streamlit, sentence_transformers, langchain-text-splitters, langchain-community, accelerate, timm, langchain, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: jupyter_client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.1 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.1 aiofiles-23.2.1 arxiv-2.1.0 cpm_kernels-1.0.11 dataclasses-json-0.6.6 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 feedparser-6.0.10 ffmpy-0.3.2 gitdb-4.0.11 gitpython-3.1.43 gradio-4.31.0 gradio-client-0.16.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 jupyter_client-8.6.1 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langchainhub-0.1.15 langsmith-0.1.57 latex2mathml-3.77.0 loguru-0.7.2 marshmallow-3.21.2 mdtex2html-1.3.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-1.28.1 orjson-3.10.3 packaging-23.2 protobuf-4.25.3 pydeck-0.9.1 pydub-0.25.1 pyjwt-2.8.0 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.4 semantic-version-2.10.0 sentence_transformers-2.7.0 sentencepiece-0.2.0 sgmllib3k-1.0.0 shellingham-1.5.4 smmap-5.0.1 sse-starlette-2.1.0 starlette-0.37.2 streamlit-1.34.0 tiktoken-0.6.0 timm-0.9.16 tomlkit-0.12.0 typer-0.12.3 types-requests-2.31.0.20240406 typing-inspect-0.9.0 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchdog-4.0.0 watchfiles-0.21.0 websockets-11.0.3 zhipuai-2.0.1.20240429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 环境检查\n",
        "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
        "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
        "\n",
        "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a7bd9a514ed09ea6"
      },
      "id": "a7bd9a514ed09ea6"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ChatGLM3/finetune_demo\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/ChatGLM3/finetune_demo')\n",
        "\n",
        "!pwd"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-14T05:29:22.200365Z",
          "start_time": "2024-04-14T05:29:22.080929Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7703109d1443346",
        "outputId": "c8fe5aa7-3118-4333-bd75-d5142c910554"
      },
      "id": "f7703109d1443346",
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 准备数据集\n",
        "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
        "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2f50e92810011977"
      },
      "id": "2f50e92810011977"
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/datasets/shibing624/AdvertiseGen"
      ],
      "metadata": {
        "id": "sZP__Abs3wu_"
      },
      "id": "sZP__Abs3wu_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv AdvertiseGen '/content/drive/MyDrive/Colab Notebooks/ChatGLM3/finetune_demo/data/'"
      ],
      "metadata": {
        "id": "tR4ZuBfD4HDa"
      },
      "id": "tR4ZuBfD4HDa",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Union\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _resolve_path(path: Union[str, Path]) -> Path:\n",
        "    return Path(path).expanduser().resolve()\n",
        "\n",
        "\n",
        "def _mkdir(dir_name: Union[str, Path]):\n",
        "    dir_name = _resolve_path(dir_name)\n",
        "    if not dir_name.is_dir():\n",
        "        dir_name.mkdir(parents=True, exist_ok=False)\n",
        "\n",
        "\n",
        "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
        "    def _convert(in_file: Path, out_file: Path):\n",
        "        _mkdir(out_file.parent)\n",
        "        with open(in_file, encoding='utf-8') as fin:\n",
        "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
        "                for line in fin:\n",
        "                    dct = json.loads(line)\n",
        "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
        "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
        "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    data_dir = _resolve_path(data_dir)\n",
        "    save_dir = _resolve_path(save_dir)\n",
        "\n",
        "    train_file = data_dir / 'train.json'\n",
        "    if train_file.is_file():\n",
        "        out_file = save_dir / train_file.relative_to(data_dir)\n",
        "        _convert(train_file, out_file)\n",
        "\n",
        "    dev_file = data_dir / 'dev.json'\n",
        "    if dev_file.is_file():\n",
        "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
        "        _convert(dev_file, out_file)\n",
        "\n",
        "\n",
        "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "initial_id",
        "ExecuteTime": {
          "end_time": "2024-04-14T05:29:23.809255Z",
          "start_time": "2024-04-14T05:29:22.202731Z"
        }
      },
      "id": "initial_id",
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
        "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a1b7a99923349056"
      },
      "id": "a1b7a99923349056"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ruamel.yaml datasets peft rouge_chinese"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1yWgK1S6S3Y",
        "outputId": "19931bf4-edb2-49e1-dddd-fce46205d853"
      },
      "id": "u1yWgK1S6S3Y",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/117.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_chinese\n",
            "  Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.30.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge_chinese) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: xxhash, ruamel.yaml.clib, rouge_chinese, dill, ruamel.yaml, multiprocess, huggingface-hub, datasets, peft\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 peft-0.10.0 rouge_chinese-1.0.3 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-12 08:40:13.926198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-12 08:40:13.926265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-12 08:40:13.927861: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-12 08:40:15.200094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 1.40k/1.40k [00:00<00:00, 8.92MB/s]\n",
            "tokenization_chatglm.py: 100% 13.0k/13.0k [00:00<00:00, 49.5MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- tokenization_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "tokenizer.model: 100% 1.02M/1.02M [00:00<00:00, 98.8MB/s]\n",
            "special_tokens_map.json: 100% 3.00/3.00 [00:00<00:00, 23.0kB/s]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "config.json: 100% 1.32k/1.32k [00:00<00:00, 9.66MB/s]\n",
            "configuration_chatglm.py: 100% 2.33k/2.33k [00:00<00:00, 16.4MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- configuration_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_chatglm.py: 100% 55.9k/55.9k [00:00<00:00, 148MB/s]\n",
            "quantization.py: 100% 14.7k/14.7k [00:00<00:00, 64.1MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- modeling_chatglm.py\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors.index.json: 100% 21.2k/21.2k [00:00<00:00, 74.3MB/s]\n",
            "Downloading shards:   0% 0/7 [00:00<?, ?it/s]\n",
            "model-00001-of-00007.safetensors:   0% 0.00/1.83G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   2% 31.5M/1.83G [00:00<00:07, 229MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   3% 62.9M/1.83G [00:00<00:08, 219MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   5% 94.4M/1.83G [00:00<00:07, 217MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   7% 126M/1.83G [00:00<00:09, 176MB/s] \u001b[A\n",
            "model-00001-of-00007.safetensors:   8% 147M/1.83G [00:00<00:09, 171MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   9% 168M/1.83G [00:00<00:09, 179MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  11% 199M/1.83G [00:01<00:08, 195MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  13% 231M/1.83G [00:01<00:07, 224MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  14% 262M/1.83G [00:01<00:06, 225MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  16% 294M/1.83G [00:01<00:06, 240MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  18% 325M/1.83G [00:01<00:05, 256MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  20% 357M/1.83G [00:01<00:05, 272MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  21% 388M/1.83G [00:01<00:06, 231MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  23% 419M/1.83G [00:01<00:05, 245MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  25% 451M/1.83G [00:02<00:05, 252MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  26% 482M/1.83G [00:02<00:05, 238MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  28% 514M/1.83G [00:02<00:05, 244MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  30% 545M/1.83G [00:02<00:05, 234MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  32% 577M/1.83G [00:02<00:05, 240MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  33% 608M/1.83G [00:02<00:05, 214MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  35% 640M/1.83G [00:02<00:05, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  37% 682M/1.83G [00:03<00:04, 241MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  39% 713M/1.83G [00:03<00:04, 250MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  41% 744M/1.83G [00:03<00:04, 261MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  42% 776M/1.83G [00:03<00:03, 270MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  44% 807M/1.83G [00:03<00:03, 257MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  46% 839M/1.83G [00:03<00:03, 257MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  48% 870M/1.83G [00:03<00:03, 254MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  49% 902M/1.83G [00:03<00:03, 254MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  52% 944M/1.83G [00:03<00:03, 274MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  53% 975M/1.83G [00:04<00:03, 260MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  55% 1.01G/1.83G [00:04<00:03, 268MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  57% 1.04G/1.83G [00:04<00:02, 272MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  59% 1.07G/1.83G [00:04<00:02, 264MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  60% 1.10G/1.83G [00:04<00:02, 272MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  62% 1.13G/1.83G [00:04<00:02, 265MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  64% 1.17G/1.83G [00:04<00:02, 275MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  66% 1.21G/1.83G [00:04<00:02, 274MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  68% 1.24G/1.83G [00:05<00:02, 268MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  69% 1.27G/1.83G [00:05<00:02, 252MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  71% 1.30G/1.83G [00:05<00:02, 256MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  73% 1.33G/1.83G [00:05<00:01, 253MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  75% 1.36G/1.83G [00:05<00:02, 230MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  76% 1.39G/1.83G [00:05<00:01, 238MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  78% 1.43G/1.83G [00:05<00:01, 237MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  80% 1.46G/1.83G [00:06<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  81% 1.49G/1.83G [00:06<00:01, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  83% 1.52G/1.83G [00:06<00:01, 223MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  85% 1.55G/1.83G [00:06<00:01, 237MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  87% 1.58G/1.83G [00:06<00:00, 253MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  89% 1.63G/1.83G [00:06<00:00, 273MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  91% 1.66G/1.83G [00:06<00:00, 281MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  92% 1.69G/1.83G [00:06<00:00, 263MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  95% 1.73G/1.83G [00:07<00:00, 280MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  96% 1.76G/1.83G [00:07<00:00, 286MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  98% 1.79G/1.83G [00:07<00:00, 281MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors: 100% 1.83G/1.83G [00:07<00:00, 246MB/s]\n",
            "Downloading shards:  14% 1/7 [00:07<00:47,  7.93s/it]\n",
            "model-00002-of-00007.safetensors:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   1% 10.5M/1.97G [00:00<01:33, 20.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   1% 21.0M/1.97G [00:00<01:32, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   2% 31.5M/1.97G [00:01<01:31, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   2% 41.9M/1.97G [00:01<01:30, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   3% 52.4M/1.97G [00:02<01:30, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   3% 62.9M/1.97G [00:02<01:29, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   4% 73.4M/1.97G [00:03<01:29, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   4% 83.9M/1.97G [00:03<01:29, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   5% 94.4M/1.97G [00:04<01:28, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   5% 105M/1.97G [00:04<01:27, 21.2MB/s] \u001b[A\n",
            "model-00002-of-00007.safetensors:   6% 115M/1.97G [00:05<01:27, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   6% 126M/1.97G [00:05<01:26, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   7% 136M/1.97G [00:06<01:26, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   7% 147M/1.97G [00:06<01:25, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   8% 157M/1.97G [00:07<01:25, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   9% 168M/1.97G [00:07<01:24, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   9% 178M/1.97G [00:08<01:24, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  10% 189M/1.97G [00:08<01:23, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  10% 199M/1.97G [00:09<01:23, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  11% 210M/1.97G [00:09<01:22, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  11% 220M/1.97G [00:10<01:22, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  12% 231M/1.97G [00:10<01:22, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  12% 241M/1.97G [00:11<01:21, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  13% 252M/1.97G [00:11<01:20, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  13% 262M/1.97G [00:12<01:20, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  14% 273M/1.97G [00:12<01:19, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  14% 283M/1.97G [00:13<01:19, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  15% 294M/1.97G [00:13<01:19, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  15% 304M/1.97G [00:14<01:18, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  16% 315M/1.97G [00:14<01:17, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  17% 325M/1.97G [00:15<01:17, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  17% 336M/1.97G [00:15<01:16, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  18% 346M/1.97G [00:16<01:16, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  18% 357M/1.97G [00:16<01:15, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  19% 367M/1.97G [00:17<01:15, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  19% 377M/1.97G [00:17<01:15, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  20% 388M/1.97G [00:18<01:14, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  20% 398M/1.97G [00:18<01:13, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  21% 409M/1.97G [00:19<01:13, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  21% 419M/1.97G [00:19<01:13, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  22% 430M/1.97G [00:20<01:12, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  22% 440M/1.97G [00:20<01:12, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  23% 451M/1.97G [00:21<01:11, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  23% 461M/1.97G [00:21<01:10, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  24% 472M/1.97G [00:22<01:12, 20.6MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  25% 482M/1.97G [00:22<01:09, 21.4MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  25% 493M/1.97G [00:23<01:09, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  26% 503M/1.97G [00:23<01:08, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  26% 514M/1.97G [00:24<01:08, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  27% 524M/1.97G [00:24<01:08, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  27% 535M/1.97G [00:25<01:07, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  28% 545M/1.97G [00:25<01:07, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  28% 556M/1.97G [00:26<01:06, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  29% 566M/1.97G [00:26<01:05, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  29% 577M/1.97G [00:27<01:05, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  30% 587M/1.97G [00:27<01:05, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  30% 598M/1.97G [00:28<01:04, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  31% 608M/1.97G [00:28<01:04, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  31% 619M/1.97G [00:29<01:03, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  32% 629M/1.97G [00:29<01:03, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  32% 640M/1.97G [00:30<01:02, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  33% 650M/1.97G [00:30<01:02, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  34% 661M/1.97G [00:31<01:01, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  34% 671M/1.97G [00:31<01:01, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  35% 682M/1.97G [00:32<01:00, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  35% 692M/1.97G [00:32<01:00, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  36% 703M/1.97G [00:33<00:59, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  36% 713M/1.97G [00:33<00:59, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  37% 724M/1.97G [00:34<00:58, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  37% 734M/1.97G [00:34<00:58, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  38% 744M/1.97G [00:35<00:57, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  38% 755M/1.97G [00:35<00:57, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  39% 765M/1.97G [00:36<00:56, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  39% 776M/1.97G [00:36<00:56, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  40% 786M/1.97G [00:37<00:55, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  40% 797M/1.97G [00:37<00:55, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  41% 807M/1.97G [00:38<00:54, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  42% 818M/1.97G [00:38<01:00, 19.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  42% 828M/1.97G [00:39<00:58, 19.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  43% 839M/1.97G [00:39<00:56, 19.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  43% 849M/1.97G [00:40<00:55, 20.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  44% 860M/1.97G [00:40<00:54, 20.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  44% 870M/1.97G [00:41<00:53, 20.7MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  45% 881M/1.97G [00:41<00:52, 20.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  45% 891M/1.97G [00:42<00:51, 20.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  46% 902M/1.97G [00:42<00:50, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  46% 912M/1.97G [00:43<00:50, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  47% 923M/1.97G [00:43<00:49, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  47% 933M/1.97G [00:44<00:48, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  48% 944M/1.97G [00:44<00:48, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  48% 954M/1.97G [00:45<00:47, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  49% 965M/1.97G [00:45<00:47, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  50% 975M/1.97G [00:46<00:46, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  50% 986M/1.97G [00:46<00:46, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  51% 996M/1.97G [00:47<00:45, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  51% 1.01G/1.97G [00:47<00:45, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  52% 1.02G/1.97G [00:48<00:44, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  52% 1.03G/1.97G [00:48<00:44, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  53% 1.04G/1.97G [00:49<00:43, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  53% 1.05G/1.97G [00:49<00:43, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  54% 1.06G/1.97G [00:50<00:42, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  54% 1.07G/1.97G [00:50<00:42, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  55% 1.08G/1.97G [00:51<00:41, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  55% 1.09G/1.97G [00:51<00:41, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  56% 1.10G/1.97G [00:52<00:40, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  56% 1.11G/1.97G [00:52<00:40, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  57% 1.12G/1.97G [00:53<00:44, 18.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  58% 1.13G/1.97G [00:53<00:42, 19.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  58% 1.14G/1.97G [00:54<00:41, 20.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  59% 1.15G/1.97G [00:54<00:40, 20.4MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  59% 1.16G/1.97G [00:55<00:38, 20.6MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  60% 1.17G/1.97G [00:55<00:38, 20.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  60% 1.18G/1.97G [00:56<00:37, 20.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  61% 1.20G/1.97G [00:56<00:36, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  61% 1.21G/1.97G [00:57<00:36, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  62% 1.22G/1.97G [00:57<00:35, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  62% 1.23G/1.97G [00:58<00:35, 20.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  63% 1.24G/1.97G [00:58<00:34, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  63% 1.25G/1.97G [00:59<00:34, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  64% 1.26G/1.97G [00:59<00:33, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  64% 1.27G/1.97G [01:00<00:33, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  65% 1.28G/1.97G [01:00<00:32, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  66% 1.29G/1.97G [01:01<00:31, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  66% 1.30G/1.97G [01:01<00:35, 18.7MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  67% 1.31G/1.97G [01:02<00:33, 19.4MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  67% 1.32G/1.97G [01:02<00:32, 19.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  68% 1.33G/1.97G [01:03<00:31, 20.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  68% 1.34G/1.97G [01:03<00:30, 20.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  69% 1.35G/1.97G [01:04<00:29, 20.7MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  69% 1.36G/1.97G [01:04<00:29, 20.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  70% 1.37G/1.97G [01:05<00:28, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  70% 1.38G/1.97G [01:05<00:27, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  71% 1.39G/1.97G [01:06<00:27, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  71% 1.41G/1.97G [01:06<00:26, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  72% 1.42G/1.97G [01:07<00:26, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  72% 1.43G/1.97G [01:07<00:25, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  73% 1.44G/1.97G [01:08<00:25, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  74% 1.45G/1.97G [01:08<00:24, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  74% 1.46G/1.97G [01:09<00:24, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  75% 1.47G/1.97G [01:09<00:23, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  75% 1.48G/1.97G [01:10<00:23, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  76% 1.49G/1.97G [01:10<00:22, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  76% 1.50G/1.97G [01:11<00:22, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  77% 1.51G/1.97G [01:11<00:21, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  77% 1.52G/1.97G [01:12<00:21, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  78% 1.53G/1.97G [01:12<00:20, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  78% 1.54G/1.97G [01:13<00:20, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  79% 1.55G/1.97G [01:13<00:19, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  79% 1.56G/1.97G [01:14<00:19, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  80% 1.57G/1.97G [01:14<00:18, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  80% 1.58G/1.97G [01:15<00:18, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  81% 1.59G/1.97G [01:15<00:17, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  82% 1.60G/1.97G [01:16<00:17, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  82% 1.61G/1.97G [01:16<00:16, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  83% 1.63G/1.97G [01:17<00:16, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  83% 1.64G/1.97G [01:17<00:15, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  84% 1.65G/1.97G [01:18<00:15, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  84% 1.66G/1.97G [01:18<00:14, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  85% 1.67G/1.97G [01:19<00:14, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  85% 1.68G/1.97G [01:19<00:13, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  86% 1.69G/1.97G [01:20<00:13, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  86% 1.70G/1.97G [01:20<00:12, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  87% 1.71G/1.97G [01:21<00:12, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  87% 1.72G/1.97G [01:21<00:11, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  88% 1.73G/1.97G [01:22<00:11, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  88% 1.74G/1.97G [01:22<00:10, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  89% 1.75G/1.97G [01:23<00:10, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  89% 1.76G/1.97G [01:23<00:09, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  90% 1.77G/1.97G [01:24<00:09, 21.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  91% 1.78G/1.97G [01:24<00:08, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  91% 1.79G/1.97G [01:25<00:08, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  92% 1.80G/1.97G [01:25<00:07, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  92% 1.81G/1.97G [01:26<00:07, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  93% 1.82G/1.97G [01:26<00:06, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  93% 1.84G/1.97G [01:27<00:06, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  94% 1.85G/1.97G [01:27<00:05, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  94% 1.86G/1.97G [01:28<00:05, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  95% 1.87G/1.97G [01:28<00:04, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  95% 1.88G/1.97G [01:29<00:04, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  96% 1.89G/1.97G [01:29<00:03, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  96% 1.90G/1.97G [01:30<00:03, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  97% 1.91G/1.97G [01:30<00:02, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  97% 1.92G/1.97G [01:31<00:02, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  98% 1.93G/1.97G [01:31<00:01, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  99% 1.94G/1.97G [01:32<00:01, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  99% 1.95G/1.97G [01:32<00:00, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors: 100% 1.96G/1.97G [01:33<00:00, 21.2MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors: 100% 1.97G/1.97G [01:33<00:00, 21.0MB/s]\n",
            "Downloading shards:  29% 2/7 [01:42<04:53, 58.64s/it]\n",
            "model-00003-of-00007.safetensors:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   1% 21.0M/1.93G [00:00<00:09, 202MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   3% 62.9M/1.93G [00:00<00:06, 282MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   5% 94.4M/1.93G [00:00<00:07, 242MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   7% 126M/1.93G [00:00<00:07, 250MB/s] \u001b[A\n",
            "model-00003-of-00007.safetensors:   8% 157M/1.93G [00:00<00:06, 262MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  10% 189M/1.93G [00:00<00:06, 271MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  11% 220M/1.93G [00:00<00:06, 277MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  13% 252M/1.93G [00:00<00:06, 270MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  15% 283M/1.93G [00:01<00:05, 279MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  16% 315M/1.93G [00:01<00:06, 266MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  18% 357M/1.93G [00:01<00:05, 299MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  20% 388M/1.93G [00:01<00:05, 300MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  22% 419M/1.93G [00:01<00:04, 303MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  23% 451M/1.93G [00:01<00:05, 273MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  25% 482M/1.93G [00:01<00:05, 276MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  27% 514M/1.93G [00:01<00:05, 271MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  28% 545M/1.93G [00:02<00:05, 265MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  30% 587M/1.93G [00:02<00:04, 284MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  32% 619M/1.93G [00:02<00:04, 277MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  34% 661M/1.93G [00:02<00:04, 305MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  36% 692M/1.93G [00:02<00:04, 305MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  38% 724M/1.93G [00:02<00:04, 292MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  39% 755M/1.93G [00:02<00:04, 276MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  41% 786M/1.93G [00:02<00:04, 274MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  42% 818M/1.93G [00:02<00:04, 266MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  44% 849M/1.93G [00:03<00:04, 251MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  46% 881M/1.93G [00:03<00:04, 233MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  47% 912M/1.93G [00:03<00:04, 217MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  49% 944M/1.93G [00:03<00:04, 199MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  50% 965M/1.93G [00:03<00:05, 192MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  51% 986M/1.93G [00:03<00:05, 186MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  53% 1.02G/1.93G [00:03<00:04, 211MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  54% 1.05G/1.93G [00:04<00:03, 235MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  56% 1.08G/1.93G [00:04<00:03, 245MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  58% 1.11G/1.93G [00:04<00:03, 231MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  59% 1.14G/1.93G [00:04<00:03, 235MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  61% 1.17G/1.93G [00:04<00:02, 252MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  63% 1.22G/1.93G [00:04<00:02, 272MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  65% 1.25G/1.93G [00:04<00:02, 271MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  66% 1.28G/1.93G [00:04<00:02, 268MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  68% 1.31G/1.93G [00:05<00:02, 276MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  70% 1.34G/1.93G [00:05<00:02, 280MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  71% 1.37G/1.93G [00:05<00:02, 269MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  73% 1.41G/1.93G [00:05<00:01, 264MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  75% 1.44G/1.93G [00:05<00:01, 265MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  76% 1.47G/1.93G [00:05<00:01, 270MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  78% 1.50G/1.93G [00:05<00:01, 260MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  79% 1.53G/1.93G [00:05<00:01, 268MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  82% 1.57G/1.93G [00:06<00:01, 286MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  83% 1.60G/1.93G [00:06<00:01, 290MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  85% 1.64G/1.93G [00:06<00:00, 293MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  87% 1.68G/1.93G [00:06<00:00, 294MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  89% 1.71G/1.93G [00:06<00:00, 268MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  91% 1.75G/1.93G [00:06<00:00, 285MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  92% 1.78G/1.93G [00:06<00:00, 264MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  94% 1.81G/1.93G [00:07<00:00, 210MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  96% 1.85G/1.93G [00:07<00:00, 217MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  97% 1.88G/1.93G [00:07<00:00, 229MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors: 100% 1.93G/1.93G [00:07<00:00, 258MB/s]\n",
            "Downloading shards:  43% 3/7 [01:50<02:22, 35.50s/it]\n",
            "model-00004-of-00007.safetensors:   0% 0.00/1.82G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   2% 31.5M/1.82G [00:00<00:05, 297MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   3% 62.9M/1.82G [00:00<00:06, 255MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   5% 94.4M/1.82G [00:00<00:06, 258MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   7% 126M/1.82G [00:00<00:06, 242MB/s] \u001b[A\n",
            "model-00004-of-00007.safetensors:   9% 157M/1.82G [00:00<00:07, 223MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  10% 189M/1.82G [00:00<00:07, 220MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  13% 231M/1.82G [00:00<00:06, 250MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  14% 262M/1.82G [00:01<00:06, 242MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  16% 294M/1.82G [00:01<00:05, 258MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  18% 325M/1.82G [00:01<00:05, 260MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  20% 357M/1.82G [00:01<00:05, 249MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  21% 388M/1.82G [00:01<00:05, 241MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  23% 419M/1.82G [00:01<00:05, 255MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  25% 451M/1.82G [00:01<00:05, 244MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  27% 482M/1.82G [00:01<00:05, 241MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  28% 514M/1.82G [00:02<00:05, 248MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  30% 545M/1.82G [00:02<00:05, 243MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  32% 577M/1.82G [00:02<00:04, 261MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  34% 608M/1.82G [00:02<00:04, 258MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  35% 640M/1.82G [00:02<00:04, 246MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  37% 671M/1.82G [00:02<00:05, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  39% 703M/1.82G [00:02<00:04, 224MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  40% 734M/1.82G [00:03<00:06, 169MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  42% 765M/1.82G [00:03<00:05, 182MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  44% 797M/1.82G [00:03<00:05, 197MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  46% 828M/1.82G [00:03<00:04, 210MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  47% 860M/1.82G [00:03<00:04, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  49% 891M/1.82G [00:03<00:04, 228MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  51% 923M/1.82G [00:03<00:03, 242MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  53% 954M/1.82G [00:04<00:03, 247MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  55% 996M/1.82G [00:04<00:03, 268MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  57% 1.04G/1.82G [00:04<00:02, 281MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  59% 1.07G/1.82G [00:04<00:02, 278MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  61% 1.10G/1.82G [00:04<00:02, 251MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  62% 1.13G/1.82G [00:04<00:03, 181MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  64% 1.16G/1.82G [00:05<00:03, 182MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  66% 1.20G/1.82G [00:05<00:03, 192MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  68% 1.23G/1.82G [00:05<00:02, 203MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  69% 1.26G/1.82G [00:05<00:02, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  71% 1.29G/1.82G [00:05<00:02, 234MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  73% 1.32G/1.82G [00:05<00:02, 229MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  75% 1.35G/1.82G [00:05<00:02, 222MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  76% 1.38G/1.82G [00:06<00:01, 238MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  78% 1.42G/1.82G [00:06<00:01, 255MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  80% 1.45G/1.82G [00:06<00:01, 270MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  81% 1.48G/1.82G [00:06<00:01, 276MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  83% 1.51G/1.82G [00:06<00:01, 246MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  85% 1.54G/1.82G [00:06<00:01, 250MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  87% 1.57G/1.82G [00:06<00:00, 253MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  88% 1.60G/1.82G [00:06<00:00, 259MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  91% 1.65G/1.82G [00:06<00:00, 282MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  92% 1.68G/1.82G [00:07<00:00, 288MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  94% 1.71G/1.82G [00:07<00:00, 260MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  96% 1.74G/1.82G [00:07<00:00, 258MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  98% 1.77G/1.82G [00:07<00:00, 266MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors: 100% 1.82G/1.82G [00:07<00:00, 238MB/s]\n",
            "Downloading shards:  57% 4/7 [01:58<01:14, 24.71s/it]\n",
            "model-00005-of-00007.safetensors:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   1% 21.0M/1.97G [00:00<00:10, 179MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   3% 52.4M/1.97G [00:00<00:08, 223MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   4% 83.9M/1.97G [00:00<00:07, 246MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   6% 115M/1.97G [00:00<00:07, 247MB/s] \u001b[A\n",
            "model-00005-of-00007.safetensors:   7% 147M/1.97G [00:00<00:07, 232MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   9% 178M/1.97G [00:00<00:07, 244MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  11% 210M/1.97G [00:00<00:07, 243MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  12% 241M/1.97G [00:00<00:06, 256MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  14% 273M/1.97G [00:01<00:07, 229MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  15% 304M/1.97G [00:01<00:06, 247MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  17% 336M/1.97G [00:01<00:06, 263MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  19% 367M/1.97G [00:01<00:06, 260MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  20% 398M/1.97G [00:01<00:06, 247MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  22% 440M/1.97G [00:01<00:05, 271MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  24% 472M/1.97G [00:01<00:05, 274MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  26% 503M/1.97G [00:02<00:05, 245MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  27% 535M/1.97G [00:02<00:05, 248MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  29% 566M/1.97G [00:02<00:05, 251MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  30% 598M/1.97G [00:02<00:05, 230MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  32% 629M/1.97G [00:02<00:06, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  34% 661M/1.97G [00:02<00:05, 236MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  35% 692M/1.97G [00:02<00:05, 236MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  37% 724M/1.97G [00:02<00:04, 253MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  38% 755M/1.97G [00:03<00:04, 254MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  40% 786M/1.97G [00:03<00:04, 253MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  42% 818M/1.97G [00:03<00:04, 249MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  43% 849M/1.97G [00:03<00:04, 235MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  45% 881M/1.97G [00:03<00:04, 242MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  46% 912M/1.97G [00:03<00:04, 231MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  48% 944M/1.97G [00:03<00:04, 238MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  50% 975M/1.97G [00:03<00:03, 251MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  51% 1.01G/1.97G [00:04<00:03, 244MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  53% 1.04G/1.97G [00:04<00:03, 239MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  54% 1.07G/1.97G [00:04<00:03, 237MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  56% 1.10G/1.97G [00:04<00:03, 221MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  58% 1.13G/1.97G [00:04<00:03, 223MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  59% 1.16G/1.97G [00:04<00:03, 240MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  61% 1.20G/1.97G [00:04<00:03, 234MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  62% 1.23G/1.97G [00:05<00:03, 227MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  64% 1.26G/1.97G [00:05<00:03, 226MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  66% 1.29G/1.97G [00:05<00:03, 213MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  67% 1.32G/1.97G [00:05<00:02, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  69% 1.35G/1.97G [00:05<00:02, 220MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  70% 1.38G/1.97G [00:05<00:02, 227MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  72% 1.43G/1.97G [00:05<00:02, 253MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  74% 1.46G/1.97G [00:06<00:02, 252MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  76% 1.49G/1.97G [00:06<00:01, 249MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  77% 1.52G/1.97G [00:06<00:01, 244MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  79% 1.55G/1.97G [00:06<00:01, 247MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  80% 1.58G/1.97G [00:06<00:01, 254MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  82% 1.61G/1.97G [00:06<00:01, 250MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  84% 1.65G/1.97G [00:06<00:01, 244MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  85% 1.68G/1.97G [00:06<00:01, 255MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  87% 1.71G/1.97G [00:07<00:01, 248MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  88% 1.74G/1.97G [00:07<00:00, 251MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  91% 1.78G/1.97G [00:07<00:00, 261MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  92% 1.81G/1.97G [00:07<00:00, 247MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  94% 1.85G/1.97G [00:07<00:00, 248MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  95% 1.88G/1.97G [00:07<00:00, 220MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  97% 1.91G/1.97G [00:07<00:00, 239MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors: 100% 1.97G/1.97G [00:08<00:00, 242MB/s]\n",
            "Downloading shards:  71% 5/7 [02:06<00:37, 18.92s/it]\n",
            "model-00006-of-00007.safetensors:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   1% 21.0M/1.93G [00:00<00:11, 170MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   2% 41.9M/1.93G [00:00<00:11, 163MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   4% 73.4M/1.93G [00:00<00:09, 192MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   5% 105M/1.93G [00:00<00:08, 218MB/s] \u001b[A\n",
            "model-00006-of-00007.safetensors:   7% 136M/1.93G [00:00<00:07, 225MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   9% 168M/1.93G [00:00<00:07, 234MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  10% 199M/1.93G [00:00<00:07, 242MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  13% 241M/1.93G [00:01<00:06, 268MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  14% 273M/1.93G [00:01<00:06, 265MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  16% 304M/1.93G [00:01<00:06, 264MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  17% 336M/1.93G [00:01<00:05, 270MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  19% 367M/1.93G [00:01<00:06, 250MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  21% 398M/1.93G [00:01<00:05, 266MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  22% 430M/1.93G [00:01<00:05, 258MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  24% 461M/1.93G [00:01<00:05, 258MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  26% 493M/1.93G [00:02<00:05, 246MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  27% 524M/1.93G [00:02<00:05, 235MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  29% 556M/1.93G [00:02<00:05, 248MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  30% 587M/1.93G [00:02<00:05, 255MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  32% 619M/1.93G [00:02<00:05, 238MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  34% 650M/1.93G [00:02<00:05, 248MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  35% 682M/1.93G [00:02<00:04, 257MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  37% 713M/1.93G [00:02<00:04, 253MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  39% 744M/1.93G [00:03<00:04, 263MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  40% 776M/1.93G [00:03<00:04, 249MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  42% 807M/1.93G [00:03<00:04, 233MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  44% 839M/1.93G [00:03<00:04, 251MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  45% 870M/1.93G [00:03<00:04, 260MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  47% 912M/1.93G [00:03<00:03, 282MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  49% 944M/1.93G [00:03<00:03, 277MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  51% 975M/1.93G [00:03<00:03, 276MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  53% 1.02G/1.93G [00:04<00:03, 282MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  54% 1.05G/1.93G [00:04<00:03, 288MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  56% 1.08G/1.93G [00:04<00:02, 283MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  58% 1.11G/1.93G [00:04<00:02, 285MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  59% 1.14G/1.93G [00:04<00:02, 275MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  61% 1.17G/1.93G [00:04<00:02, 272MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  63% 1.21G/1.93G [00:04<00:02, 267MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  64% 1.24G/1.93G [00:04<00:02, 275MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  66% 1.28G/1.93G [00:04<00:02, 282MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  68% 1.31G/1.93G [00:05<00:02, 283MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  70% 1.34G/1.93G [00:05<00:02, 268MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  71% 1.37G/1.93G [00:05<00:02, 254MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  73% 1.41G/1.93G [00:05<00:02, 230MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  75% 1.45G/1.93G [00:05<00:01, 248MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  77% 1.49G/1.93G [00:05<00:01, 273MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  79% 1.52G/1.93G [00:05<00:01, 244MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  81% 1.55G/1.93G [00:06<00:01, 237MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  82% 1.58G/1.93G [00:06<00:01, 251MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  84% 1.61G/1.93G [00:06<00:01, 260MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  85% 1.65G/1.93G [00:06<00:01, 255MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  87% 1.68G/1.93G [00:06<00:01, 235MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  89% 1.71G/1.93G [00:06<00:00, 254MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  91% 1.75G/1.93G [00:06<00:00, 279MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  92% 1.78G/1.93G [00:06<00:00, 268MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  94% 1.81G/1.93G [00:07<00:00, 255MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  96% 1.85G/1.93G [00:07<00:00, 218MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  97% 1.88G/1.93G [00:07<00:00, 230MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors: 100% 1.93G/1.93G [00:07<00:00, 254MB/s]\n",
            "Downloading shards:  86% 6/7 [02:15<00:15, 15.30s/it]\n",
            "model-00007-of-00007.safetensors:   0% 0.00/1.05G [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   2% 21.0M/1.05G [00:00<00:05, 194MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   4% 41.9M/1.05G [00:00<00:09, 103MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   7% 73.4M/1.05G [00:00<00:06, 154MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  10% 105M/1.05G [00:00<00:05, 184MB/s] \u001b[A\n",
            "model-00007-of-00007.safetensors:  12% 126M/1.05G [00:00<00:05, 170MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  14% 147M/1.05G [00:00<00:05, 164MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  17% 178M/1.05G [00:01<00:04, 190MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  20% 210M/1.05G [00:01<00:04, 200MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  22% 231M/1.05G [00:01<00:04, 172MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  24% 252M/1.05G [00:01<00:04, 163MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  26% 273M/1.05G [00:01<00:04, 170MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  28% 294M/1.05G [00:01<00:04, 174MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  30% 315M/1.05G [00:01<00:04, 179MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  33% 346M/1.05G [00:01<00:03, 204MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  36% 377M/1.05G [00:02<00:03, 211MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  39% 409M/1.05G [00:02<00:02, 221MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  42% 440M/1.05G [00:02<00:02, 224MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  45% 472M/1.05G [00:02<00:02, 213MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  48% 503M/1.05G [00:02<00:02, 236MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  51% 535M/1.05G [00:02<00:02, 253MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  54% 566M/1.05G [00:02<00:01, 257MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  57% 598M/1.05G [00:02<00:01, 264MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  60% 629M/1.05G [00:03<00:01, 269MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  63% 661M/1.05G [00:03<00:01, 271MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  66% 692M/1.05G [00:03<00:01, 267MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  69% 724M/1.05G [00:03<00:01, 271MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  72% 755M/1.05G [00:03<00:01, 264MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  75% 786M/1.05G [00:03<00:00, 268MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  79% 828M/1.05G [00:03<00:00, 291MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  83% 870M/1.05G [00:03<00:00, 299MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  86% 902M/1.05G [00:04<00:00, 285MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  90% 944M/1.05G [00:04<00:00, 313MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  94% 986M/1.05G [00:04<00:00, 311MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  97% 1.02G/1.05G [00:04<00:00, 295MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors: 100% 1.05G/1.05G [00:04<00:00, 233MB/s]\n",
            "Downloading shards: 100% 7/7 [02:20<00:00, 20.02s/it]\n",
            "Loading checkpoint shards: 100% 7/7 [00:03<00:00,  2.01it/s]\n",
            "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
            "--> Model\n",
            "\n",
            "--> model has 1.949696M params\n",
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 114599 examples [00:00, 519691.34 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
            "Generating validation split: 1070 examples [00:00, 159106.08 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
            "Generating test split: 1070 examples [00:00, 170318.99 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Map (num_proc=16): 100% 114599/114599 [00:04<00:00, 25758.93 examples/s]\n",
            "train_dataset: Dataset({\n",
            "    features: ['input_ids', 'labels'],\n",
            "    num_rows: 114599\n",
            "})\n",
            "Map (num_proc=16): 100% 1070/1070 [00:00<00:00, 1287.66 examples/s]\n",
            "val_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "Map (num_proc=16): 100% 1070/1070 [00:00<00:00, 1308.40 examples/s]\n",
            "test_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "--> Sanity check\n",
            "           '[gMASK]': 64790 -> -100\n",
            "               'sop': 64792 -> -100\n",
            "          '<|user|>': 64795 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '\\n': 13 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '类型': 33467 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '版': 55090 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '宽松': 40833 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '风格': 32799 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '性感': 40589 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '图案': 37505 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '线条': 37216 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '阔': 56529 -> -100\n",
            "                 '腿': 56158 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "     '<|assistant|>': 64796 -> -100\n",
            "                  '': 30910 -> 30910\n",
            "                '\\n': 13 -> 13\n",
            "                  '': 30910 -> 30910\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '阔': 56529 -> 56529\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '这': 54551 -> 54551\n",
            "                '两年': 33808 -> 33808\n",
            "                '真的': 32041 -> 32041\n",
            "                 '吸': 55360 -> 55360\n",
            "                 '粉': 55486 -> 55486\n",
            "                '不少': 32138 -> 32138\n",
            "                 '，': 31123 -> 31123\n",
            "                '明星': 32943 -> 32943\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '达': 54880 -> 54880\n",
            "                '人的': 31664 -> 31664\n",
            "                '心头': 46565 -> 46565\n",
            "                 '爱': 54799 -> 54799\n",
            "                 '。': 31155 -> 31155\n",
            "                '毕竟': 33051 -> 33051\n",
            "                 '好': 54591 -> 54591\n",
            "                 '穿': 55432 -> 55432\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '，': 31123 -> 31123\n",
            "                 '谁': 55622 -> 55622\n",
            "                '都能': 32904 -> 32904\n",
            "                 '穿': 55432 -> 55432\n",
            "                 '出': 54557 -> 54557\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '长': 54625 -> 54625\n",
            "                 '2': 30943 -> 30943\n",
            "                 '米': 55055 -> 55055\n",
            "               '的效果': 35590 -> 35590\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '，': 31123 -> 31123\n",
            "               '当然是': 48466 -> 48466\n",
            "                 '遮': 57148 -> 57148\n",
            "                 '肉': 55343 -> 55343\n",
            "                 '小': 54603 -> 54603\n",
            "                '能手': 49355 -> 49355\n",
            "                 '啊': 55674 -> 55674\n",
            "                 '。': 31155 -> 31155\n",
            "                '上身': 51605 -> 51605\n",
            "                 '随': 55119 -> 55119\n",
            "                 '性': 54642 -> 54642\n",
            "                '自然': 31799 -> 31799\n",
            "                 '不': 54535 -> 54535\n",
            "                 '拘': 57036 -> 57036\n",
            "                 '束': 55625 -> 55625\n",
            "                 '，': 31123 -> 31123\n",
            "                '面料': 46839 -> 46839\n",
            "                 '亲': 55113 -> 55113\n",
            "                 '肤': 56089 -> 56089\n",
            "                '舒适': 33894 -> 33894\n",
            "                 '贴': 55778 -> 55778\n",
            "                '身体': 31902 -> 31902\n",
            "                 '验': 55017 -> 55017\n",
            "                 '感': 54706 -> 54706\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '哒': 59230 -> 59230\n",
            "                 '。': 31155 -> 31155\n",
            "                 '系': 54712 -> 54712\n",
            "                 '带': 54882 -> 54882\n",
            "                '部分': 31726 -> 31726\n",
            "                '增加': 31917 -> 31917\n",
            "                '设计': 31735 -> 31735\n",
            "                '看点': 45032 -> 45032\n",
            "                 '，': 31123 -> 31123\n",
            "                 '还': 54656 -> 54656\n",
            "                 '让': 54772 -> 54772\n",
            "                '单品': 46539 -> 46539\n",
            "               '的设计': 34481 -> 34481\n",
            "                 '感': 54706 -> 54706\n",
            "                '更强': 43084 -> 43084\n",
            "                 '。': 31155 -> 31155\n",
            "                '腿部': 46799 -> 46799\n",
            "                '线条': 37216 -> 37216\n",
            "                 '若': 55351 -> 55351\n",
            "                 '隐': 55733 -> 55733\n",
            "                 '若': 55351 -> 55351\n",
            "                 '现': 54600 -> 54600\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                '性感': 40589 -> 40589\n",
            "                 '撩': 58521 -> 58521\n",
            "                 '人': 54533 -> 54533\n",
            "                 '。': 31155 -> 31155\n",
            "                '颜色': 33692 -> 33692\n",
            "                 '敲': 57004 -> 57004\n",
            "                '温柔': 34678 -> 34678\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                 '与': 54619 -> 54619\n",
            "                '裤子': 44722 -> 44722\n",
            "                '本身': 32754 -> 32754\n",
            "                 '所': 54626 -> 54626\n",
            "                '呈现': 33169 -> 33169\n",
            "               '的风格': 48084 -> 48084\n",
            "                '有点': 33149 -> 33149\n",
            "                 '反': 54955 -> 54955\n",
            "                 '差': 55342 -> 55342\n",
            "                 '萌': 56842 -> 56842\n",
            "                 '。': 31155 -> 31155\n",
            "                  '': 2 -> 2\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running training *****\n",
            "  Num examples = 114,599\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3,000\n",
            "  Number of trainable parameters = 1,949,696\n",
            "  0% 0/3000 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "{'loss': 4.8305, 'grad_norm': 2.209015130996704, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
            "{'loss': 4.6, 'grad_norm': 3.195251941680908, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 4.4828, 'grad_norm': 3.0088579654693604, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
            "{'loss': 4.1186, 'grad_norm': 3.3647141456604004, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 4.1174, 'grad_norm': 2.74029278755188, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8699, 'grad_norm': 2.955530881881714, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
            "{'loss': 3.841, 'grad_norm': 2.866299629211426, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 3.7488, 'grad_norm': 2.933058738708496, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6359, 'grad_norm': 3.182115316390991, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
            "{'loss': 3.7213, 'grad_norm': 3.38964581489563, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 3.673, 'grad_norm': 3.5696024894714355, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8477, 'grad_norm': 3.8596088886260986, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6168, 'grad_norm': 3.4512341022491455, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
            "{'loss': 3.7326, 'grad_norm': 4.415026664733887, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 3.682, 'grad_norm': 3.6127164363861084, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
            "{'loss': 3.7437, 'grad_norm': 3.9042351245880127, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
            "{'loss': 3.575, 'grad_norm': 4.10846471786499, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5754, 'grad_norm': 4.302988529205322, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5518, 'grad_norm': 4.800393104553223, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.577, 'grad_norm': 4.5369343757629395, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.551, 'grad_norm': 4.920289039611816, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6475, 'grad_norm': 4.0517683029174805, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6092, 'grad_norm': 4.71093225479126, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5084, 'grad_norm': 4.547570705413818, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4762, 'grad_norm': 5.365715026855469, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6021, 'grad_norm': 5.317929744720459, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5488, 'grad_norm': 5.37794303894043, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6133, 'grad_norm': 4.470576286315918, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6279, 'grad_norm': 4.753432273864746, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5365, 'grad_norm': 5.881764888763428, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4676, 'grad_norm': 5.323846340179443, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6068, 'grad_norm': 5.761098861694336, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4158, 'grad_norm': 5.171919822692871, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4912, 'grad_norm': 5.392437934875488, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5209, 'grad_norm': 5.526531219482422, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5752, 'grad_norm': 5.171678066253662, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
            "{'loss': 3.3611, 'grad_norm': 4.850843906402588, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5275, 'grad_norm': 5.146999359130859, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5252, 'grad_norm': 5.326272964477539, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4721, 'grad_norm': 5.621377468109131, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6908, 'grad_norm': 5.516353130340576, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4963, 'grad_norm': 5.058271884918213, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6262, 'grad_norm': 5.65153694152832, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4195, 'grad_norm': 6.54105806350708, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4146, 'grad_norm': 6.088809013366699, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4262, 'grad_norm': 5.5569682121276855, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5295, 'grad_norm': 5.7151198387146, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4479, 'grad_norm': 6.927011966705322, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4598, 'grad_norm': 5.813726425170898, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5633, 'grad_norm': 5.977992534637451, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
            " 17% 500/3000 [01:43<09:28,  4.40it/s]***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.71s/it]\u001b[A\n",
            " 75% 3/4 [00:42<00:15, 15.16s/it]\u001b[A\n",
            "100% 4/4 [01:04<00:00, 17.53s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.759 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "\n",
            "{'eval_rouge-1': 31.11303, 'eval_rouge-2': 6.926852, 'eval_rouge-l': 22.879484, 'eval_bleu-4': 0.02944109337903934, 'eval_runtime': 87.383, 'eval_samples_per_second': 0.572, 'eval_steps_per_second': 0.046, 'epoch': 0.02}\n",
            "\n",
            " 17% 500/3000 [03:10<09:28,  4.40it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.3189, 'grad_norm': 5.775296688079834, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5488, 'grad_norm': 6.698172569274902, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5828, 'grad_norm': 6.0308685302734375, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4855, 'grad_norm': 5.387997627258301, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5262, 'grad_norm': 5.368502616882324, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.6465, 'grad_norm': 5.752870082855225, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4949, 'grad_norm': 5.807659149169922, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3691, 'grad_norm': 5.496214389801025, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4273, 'grad_norm': 6.195023059844971, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.493, 'grad_norm': 6.52551794052124, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
            "{'loss': 3.441, 'grad_norm': 6.288242816925049, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4535, 'grad_norm': 6.527837753295898, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4482, 'grad_norm': 6.012574195861816, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4578, 'grad_norm': 6.339416980743408, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5326, 'grad_norm': 5.95430850982666, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4842, 'grad_norm': 6.3918256759643555, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5418, 'grad_norm': 6.126739978790283, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3023, 'grad_norm': 7.167820930480957, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4, 'grad_norm': 6.6601152420043945, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3488, 'grad_norm': 6.208371639251709, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4998, 'grad_norm': 7.030521869659424, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5285, 'grad_norm': 6.786877155303955, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2488, 'grad_norm': 6.976093292236328, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5723, 'grad_norm': 5.898365020751953, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.398, 'grad_norm': 6.542482376098633, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4805, 'grad_norm': 6.110260963439941, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.6219, 'grad_norm': 6.433497905731201, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4711, 'grad_norm': 6.352597713470459, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3268, 'grad_norm': 6.437525272369385, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5512, 'grad_norm': 6.896156311035156, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2926, 'grad_norm': 6.764766693115234, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3604, 'grad_norm': 6.5105485916137695, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4602, 'grad_norm': 7.25488805770874, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4111, 'grad_norm': 6.273361682891846, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5059, 'grad_norm': 6.28496789932251, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5395, 'grad_norm': 6.237421035766602, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2941, 'grad_norm': 7.113568305969238, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4898, 'grad_norm': 6.712049961090088, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4574, 'grad_norm': 7.628092288970947, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.265, 'grad_norm': 8.03205680847168, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4635, 'grad_norm': 7.823463439941406, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4174, 'grad_norm': 6.9893927574157715, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4637, 'grad_norm': 7.488393306732178, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5668, 'grad_norm': 7.267969608306885, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3684, 'grad_norm': 6.466159820556641, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4389, 'grad_norm': 7.939543724060059, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5348, 'grad_norm': 5.8916730880737305, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3199, 'grad_norm': 6.957011699676514, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4639, 'grad_norm': 7.296865463256836, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3939, 'grad_norm': 7.864221572875977, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
            " 33% 1000/3000 [04:51<06:56,  4.80it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.77s/it]\u001b[A\n",
            " 75% 3/4 [00:24<00:07,  7.55s/it]\u001b[A\n",
            "100% 4/4 [00:46<00:00, 12.77s/it]\u001b[A\n",
            "{'eval_rouge-1': 31.63041, 'eval_rouge-2': 6.396114, 'eval_rouge-l': 24.492167999999996, 'eval_bleu-4': 0.03169953520776167, 'eval_runtime': 49.9192, 'eval_samples_per_second': 1.002, 'eval_steps_per_second': 0.08, 'epoch': 0.03}\n",
            "\n",
            " 33% 1000/3000 [05:41<06:56,  4.80it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.4457, 'grad_norm': 6.95090913772583, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4553, 'grad_norm': 7.370730876922607, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
            "{'loss': 3.6527, 'grad_norm': 8.225652694702148, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4102, 'grad_norm': 6.460363388061523, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3877, 'grad_norm': 8.85767936706543, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3561, 'grad_norm': 7.72911262512207, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3867, 'grad_norm': 7.140655040740967, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4672, 'grad_norm': 7.23716402053833, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
            "{'loss': 3.5271, 'grad_norm': 7.133552074432373, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4674, 'grad_norm': 6.530800819396973, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3512, 'grad_norm': 6.850438117980957, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
            "{'loss': 3.5271, 'grad_norm': 8.019062995910645, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4318, 'grad_norm': 7.42277717590332, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3615, 'grad_norm': 7.9021172523498535, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3172, 'grad_norm': 7.581585884094238, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3563, 'grad_norm': 7.11941385269165, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4561, 'grad_norm': 6.760162353515625, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4723, 'grad_norm': 6.392115592956543, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3564, 'grad_norm': 6.628530502319336, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4115, 'grad_norm': 6.448654651641846, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2424, 'grad_norm': 6.609194755554199, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3406, 'grad_norm': 7.347039222717285, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3762, 'grad_norm': 7.411176681518555, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3756, 'grad_norm': 9.189640998840332, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4453, 'grad_norm': 6.7737016677856445, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2779, 'grad_norm': 7.646985054016113, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4539, 'grad_norm': 7.344172477722168, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3342, 'grad_norm': 7.44986629486084, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3889, 'grad_norm': 6.850250244140625, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4854, 'grad_norm': 7.6070237159729, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4627, 'grad_norm': 7.026789665222168, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4547, 'grad_norm': 6.68983793258667, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
            "{'loss': 3.401, 'grad_norm': 10.332257270812988, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3025, 'grad_norm': 7.518357276916504, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3533, 'grad_norm': 7.634339332580566, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2969, 'grad_norm': 8.078673362731934, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.516, 'grad_norm': 7.214601993560791, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3912, 'grad_norm': 7.317715167999268, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3617, 'grad_norm': 7.237119197845459, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4172, 'grad_norm': 6.76589298248291, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3469, 'grad_norm': 7.5558857917785645, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2658, 'grad_norm': 7.745453834533691, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3826, 'grad_norm': 7.784468173980713, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3617, 'grad_norm': 7.248690128326416, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2656, 'grad_norm': 6.861827850341797, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3926, 'grad_norm': 7.165966033935547, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4377, 'grad_norm': 9.764054298400879, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3016, 'grad_norm': 6.830967426300049, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4389, 'grad_norm': 7.423357963562012, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4557, 'grad_norm': 6.829444885253906, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
            " 50% 1500/3000 [07:22<04:32,  5.50it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.72s/it]\u001b[A\n",
            " 75% 3/4 [00:07<00:02,  2.56s/it]\u001b[A\n",
            "100% 4/4 [00:09<00:00,  2.55s/it]\u001b[A\n",
            "{'eval_rouge-1': 31.98813, 'eval_rouge-2': 6.615101999999999, 'eval_rouge-l': 24.890932, 'eval_bleu-4': 0.0330058352307042, 'eval_runtime': 32.1347, 'eval_samples_per_second': 1.556, 'eval_steps_per_second': 0.124, 'epoch': 0.05}\n",
            "\n",
            " 50% 1500/3000 [07:54<04:32,  5.50it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.3443, 'grad_norm': 7.026052951812744, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3891, 'grad_norm': 8.12710189819336, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4406, 'grad_norm': 8.249480247497559, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4037, 'grad_norm': 7.111279487609863, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4959, 'grad_norm': 7.4804205894470215, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4043, 'grad_norm': 8.440735816955566, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4678, 'grad_norm': 7.997350692749023, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4361, 'grad_norm': 7.74139404296875, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.51, 'grad_norm': 9.697553634643555, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3937, 'grad_norm': 7.181836128234863, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3643, 'grad_norm': 8.134737968444824, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.368, 'grad_norm': 8.472845077514648, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4746, 'grad_norm': 7.4128499031066895, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3213, 'grad_norm': 7.98962926864624, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3707, 'grad_norm': 7.607561111450195, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3049, 'grad_norm': 7.203342437744141, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4775, 'grad_norm': 8.545363426208496, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3709, 'grad_norm': 7.262650489807129, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3768, 'grad_norm': 7.5906147956848145, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5197, 'grad_norm': 7.141613483428955, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4625, 'grad_norm': 7.387117385864258, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
            "{'loss': 3.502, 'grad_norm': 7.5499749183654785, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3996, 'grad_norm': 7.540503978729248, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4002, 'grad_norm': 7.410567760467529, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4744, 'grad_norm': 7.588723659515381, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4445, 'grad_norm': 7.899413585662842, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3619, 'grad_norm': 8.057564735412598, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3584, 'grad_norm': 8.204147338867188, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3959, 'grad_norm': 8.235416412353516, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3348, 'grad_norm': 7.900559425354004, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3822, 'grad_norm': 9.073887825012207, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3471, 'grad_norm': 7.675321578979492, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5826, 'grad_norm': 8.048149108886719, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3467, 'grad_norm': 8.612249374389648, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4955, 'grad_norm': 9.285483360290527, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3818, 'grad_norm': 7.472184181213379, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3158, 'grad_norm': 8.239951133728027, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3084, 'grad_norm': 7.563401699066162, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4062, 'grad_norm': 7.490710258483887, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3748, 'grad_norm': 7.938543319702148, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3984, 'grad_norm': 8.120104789733887, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4814, 'grad_norm': 7.56650447845459, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2818, 'grad_norm': 7.911004543304443, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.5014, 'grad_norm': 7.707107067108154, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3625, 'grad_norm': 7.115854740142822, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2836, 'grad_norm': 8.73780632019043, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3721, 'grad_norm': 7.769710540771484, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
            "{'loss': 3.242, 'grad_norm': 7.8183183670043945, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4227, 'grad_norm': 7.231566905975342, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4631, 'grad_norm': 8.044849395751953, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
            " 67% 2000/3000 [09:35<03:16,  5.08it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.86s/it]\u001b[A\n",
            " 75% 3/4 [00:25<00:07,  7.89s/it]\u001b[A\n",
            "100% 4/4 [00:47<00:00, 13.00s/it]\u001b[A\n",
            "{'eval_rouge-1': 31.207608000000004, 'eval_rouge-2': 6.616454000000001, 'eval_rouge-l': 23.531366, 'eval_bleu-4': 0.03188572432489556, 'eval_runtime': 69.4188, 'eval_samples_per_second': 0.72, 'eval_steps_per_second': 0.058, 'epoch': 0.07}\n",
            "\n",
            " 67% 2000/3000 [10:44<03:16,  5.08it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.3859, 'grad_norm': 8.94257640838623, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4967, 'grad_norm': 7.685019493103027, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
            "{'loss': 3.5572, 'grad_norm': 8.9573974609375, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4957, 'grad_norm': 8.366373062133789, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3705, 'grad_norm': 8.244288444519043, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3279, 'grad_norm': 7.850134372711182, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4412, 'grad_norm': 8.173129081726074, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4215, 'grad_norm': 8.298696517944336, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4383, 'grad_norm': 7.47882604598999, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3568, 'grad_norm': 7.804096698760986, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2975, 'grad_norm': 7.830891132354736, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
            "{'loss': 3.585, 'grad_norm': 8.034584045410156, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2574, 'grad_norm': 7.669220924377441, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3607, 'grad_norm': 8.37920093536377, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4014, 'grad_norm': 7.468440532684326, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.516, 'grad_norm': 8.30133056640625, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3945, 'grad_norm': 7.051299095153809, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4188, 'grad_norm': 7.799861431121826, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3527, 'grad_norm': 7.942758083343506, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4375, 'grad_norm': 7.632676124572754, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4518, 'grad_norm': 7.041451454162598, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4184, 'grad_norm': 7.800112247467041, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4215, 'grad_norm': 8.266361236572266, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3748, 'grad_norm': 8.230522155761719, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2432, 'grad_norm': 8.407174110412598, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3617, 'grad_norm': 8.030502319335938, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4301, 'grad_norm': 8.83668041229248, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.467, 'grad_norm': 7.751382827758789, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2938, 'grad_norm': 8.384538650512695, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3611, 'grad_norm': 8.676283836364746, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3217, 'grad_norm': 8.535285949707031, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3271, 'grad_norm': 8.53980827331543, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3717, 'grad_norm': 9.079431533813477, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.367, 'grad_norm': 7.783717632293701, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2711, 'grad_norm': 8.858328819274902, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3838, 'grad_norm': 8.495438575744629, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3561, 'grad_norm': 8.008439064025879, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4963, 'grad_norm': 8.776777267456055, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.234, 'grad_norm': 8.565912246704102, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4561, 'grad_norm': 7.910213470458984, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4619, 'grad_norm': 8.173450469970703, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
            "{'loss': 3.2836, 'grad_norm': 8.144731521606445, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
            "{'loss': 3.3699, 'grad_norm': 7.408992767333984, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
            "{'loss': 3.3818, 'grad_norm': 8.10071849822998, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.275, 'grad_norm': 7.742285251617432, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3164, 'grad_norm': 7.885623455047607, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2605, 'grad_norm': 8.814553260803223, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4387, 'grad_norm': 7.556033134460449, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4752, 'grad_norm': 7.907285213470459, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3937, 'grad_norm': 9.957986831665039, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
            " 83% 2500/3000 [12:25<01:37,  5.11it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.84s/it]\u001b[A\n",
            " 75% 3/4 [00:43<00:15, 15.32s/it]\u001b[A\n",
            "100% 4/4 [00:45<00:00, 10.62s/it]\u001b[A\n",
            "{'eval_rouge-1': 32.508854, 'eval_rouge-2': 6.46559, 'eval_rouge-l': 24.355439999999998, 'eval_bleu-4': 0.029293705959677233, 'eval_runtime': 68.5244, 'eval_samples_per_second': 0.73, 'eval_steps_per_second': 0.058, 'epoch': 0.09}\n",
            "\n",
            " 83% 2500/3000 [13:33<01:37,  5.11it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.3014, 'grad_norm': 8.449603080749512, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3367, 'grad_norm': 10.626446723937988, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2492, 'grad_norm': 8.156332015991211, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.398, 'grad_norm': 8.513656616210938, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3902, 'grad_norm': 7.756755352020264, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4023, 'grad_norm': 8.410900115966797, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4678, 'grad_norm': 8.022875785827637, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4867, 'grad_norm': 8.69035816192627, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3744, 'grad_norm': 8.685164451599121, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4744, 'grad_norm': 8.769643783569336, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3531, 'grad_norm': 8.279508590698242, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4262, 'grad_norm': 7.85903787612915, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.5244, 'grad_norm': 7.629399299621582, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4459, 'grad_norm': 8.615249633789062, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4102, 'grad_norm': 8.163056373596191, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.351, 'grad_norm': 8.11142635345459, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4107, 'grad_norm': 8.844067573547363, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2734, 'grad_norm': 7.630780220031738, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4691, 'grad_norm': 8.692544937133789, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4492, 'grad_norm': 9.228493690490723, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4295, 'grad_norm': 8.45435619354248, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2506, 'grad_norm': 7.7580485343933105, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3816, 'grad_norm': 8.142443656921387, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3887, 'grad_norm': 8.269261360168457, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4594, 'grad_norm': 9.110161781311035, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3988, 'grad_norm': 8.23305892944336, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3502, 'grad_norm': 8.348956108093262, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2646, 'grad_norm': 8.584803581237793, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2816, 'grad_norm': 8.315377235412598, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2396, 'grad_norm': 7.972331523895264, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4482, 'grad_norm': 7.791057586669922, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3754, 'grad_norm': 8.13667106628418, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3891, 'grad_norm': 8.143763542175293, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4438, 'grad_norm': 9.368012428283691, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4064, 'grad_norm': 8.782247543334961, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3352, 'grad_norm': 8.471022605895996, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3752, 'grad_norm': 8.782212257385254, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.5123, 'grad_norm': 9.196351051330566, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
            "{'loss': 3.307, 'grad_norm': 8.205222129821777, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3301, 'grad_norm': 9.0888671875, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3045, 'grad_norm': 8.112079620361328, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2486, 'grad_norm': 7.387870788574219, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.359, 'grad_norm': 9.316669464111328, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2588, 'grad_norm': 8.378077507019043, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3816, 'grad_norm': 8.195879936218262, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
            "{'loss': 3.2102, 'grad_norm': 8.963469505310059, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4561, 'grad_norm': 8.97524642944336, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4312, 'grad_norm': 9.111481666564941, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4768, 'grad_norm': 8.208683967590332, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
            "{'loss': 3.3652, 'grad_norm': 8.029537200927734, 'learning_rate': 0.0, 'epoch': 0.1}\n",
            "100% 3000/3000 [15:14<00:00,  5.27it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:04<00:04,  2.01s/it]\u001b[A\n",
            " 75% 3/4 [00:25<00:10, 10.10s/it]\u001b[A\n",
            "100% 4/4 [00:47<00:00, 14.38s/it]\u001b[A\n",
            "{'eval_rouge-1': 31.724758, 'eval_rouge-2': 6.680122, 'eval_rouge-l': 23.656631999999995, 'eval_bleu-4': 0.031039373788784387, 'eval_runtime': 69.5426, 'eval_samples_per_second': 0.719, 'eval_steps_per_second': 0.058, 'epoch': 0.1}\n",
            "\n",
            "100% 3000/3000 [16:24<00:00,  5.27it/s]\n",
            "                                 \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 985.477, 'train_samples_per_second': 12.177, 'train_steps_per_second': 3.044, 'train_loss': 3.4469453125, 'epoch': 0.1}\n",
            "100% 3000/3000 [16:25<00:00,  3.05it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1070\n",
            "  Batch size = 16\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100% 67/67 [16:26<00:00, 14.73s/it]\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/lora.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17c87410a24d844f",
        "outputId": "5de2c71b-2802-481e-df2b-a54e74c5179a",
        "ExecuteTime": {
          "end_time": "2024-04-14T06:23:41.282431Z",
          "start_time": "2024-04-14T05:29:23.810692Z"
        }
      },
      "id": "17c87410a24d844f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 使用微调的数据集进行推理\n",
        "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
        "我们选择最后一轮的微调权重，并使用inference进行导入。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d9418f6c5c264601"
      },
      "id": "d9418f6c5c264601"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 7/7 [00:05<00:00,  1.39it/s]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "2024-05-12 09:18:52.677514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-12 09:18:52.677572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-12 09:18:52.679465: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-12 09:18:53.907202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "时尚感十足的套头连衣裙，轻松穿出性感大方的气质。压褶网纱的拼接设计，让连衣裙充满设计感，别致时尚。袖口和衣身的不规则压褶设计，让连衣裙更具有层次感，搭配木耳边装饰，尽显优雅气质。裙摆的百褶设计，轻松遮肉显瘦，拉链门襟设计，方便穿脱，穿着方便又美观。\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-3000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
      ],
      "metadata": {
        "id": "5060015c24e97ae",
        "outputId": "905ae1d0-e133-4e16-929d-bdb7257d5921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "ExecuteTime": {
          "end_time": "2024-04-14T06:23:52.725227Z",
          "start_time": "2024-04-14T06:23:41.284552Z"
        }
      },
      "id": "5060015c24e97ae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 总结\n",
        "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
        "在本章节中，你将会学会：\n",
        "+ 如何使用模型进行 Lora 微调\n",
        "+ 微调数据集的准备和对齐\n",
        "+ 使用微调的模型进行推理"
      ],
      "metadata": {
        "collapsed": false,
        "id": "18cd83087f096094"
      },
      "id": "18cd83087f096094"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}